{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff78029f-d5c3-4298-a8a2-a9079769becd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:05.381301Z",
     "iopub.status.busy": "2023-12-04T02:33:05.380973Z",
     "iopub.status.idle": "2023-12-04T02:33:07.919714Z",
     "shell.execute_reply": "2023-12-04T02:33:07.918551Z",
     "shell.execute_reply.started": "2023-12-04T02:33:05.381275Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import MutableMapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Iterable, Mapping\r\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n",
      "  from collections import Sized\r\n"
     ]
    }
   ],
   "source": [
    "#导入一些必要的包\n",
    "import os\n",
    "import random\n",
    "import paddle \n",
    "from paddle import nn\n",
    "from paddle import optimizer as optim \n",
    "from paddle import fluid\n",
    "\n",
    "#import paddle.vision.datasets as dset\n",
    "#import paddle.vision.transforms as transforms\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "from matplotlib import animation \n",
    "#import matplotlib.animation as animation\n",
    "\n",
    "from tqdm import tqdm\n",
    "from util.model import Generator,Discriminator,GeluGenerator,Generator256, SELUGenerator\n",
    "\n",
    "#from util.config import BATCH_SIZE, INPUT_SIZE, MAX_VAL,STEPS,ADV_MUL,OUTPUT_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ccddbb-bf99-493e-90a1-fc14def22406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:07.922063Z",
     "iopub.status.busy": "2023-12-04T02:33:07.921212Z",
     "iopub.status.idle": "2023-12-04T02:33:07.926955Z",
     "shell.execute_reply": "2023-12-04T02:33:07.926094Z",
     "shell.execute_reply.started": "2023-12-04T02:33:07.922028Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 32\n",
    "OUTPUT_SIZE = 256\n",
    "OUTPUT_SIZE_512 = 512\n",
    "\n",
    "#OUTPUT_BITS = 16\n",
    "MAX_VAL = 256\n",
    "ADV_MUL = 3\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.02\n",
    "#DISC_WIDTH = 32\n",
    "\n",
    "STEPS = 3000\n",
    "# main settings\n",
    "NUMBER_OF_BITS_PRODUCED = 1024000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde02053-d7ae-451f-ba0e-84d37dc6da9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:07.928367Z",
     "iopub.status.busy": "2023-12-04T02:33:07.928001Z",
     "iopub.status.idle": "2023-12-04T02:33:11.426838Z",
     "shell.execute_reply": "2023-12-04T02:33:11.425641Z",
     "shell.execute_reply.started": "2023-12-04T02:33:07.928342Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirror.baidu.com/pypi/simple/, https://mirrors.aliyun.com/pypi/simple/, https://pypi.tuna.tsinghua.edu.cn/simple/\r\n",
      "Requirement already satisfied: visualdl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.4.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (1.1.5)\r\n",
      "Requirement already satisfied: Pillow>=7.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (8.2.0)\r\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (3.20.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (2.2.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (1.19.5)\r\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (1.1.1)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (1.16.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (2.24.0)\r\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (0.8.53)\r\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl) (1.0.0)\r\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl) (3.0.0)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl) (1.1.0)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl) (8.0.4)\r\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl) (0.16.0)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl) (2019.3)\r\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl) (2.8.0)\r\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl) (0.18.0)\r\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl) (3.9.9)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->visualdl) (2.8.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl) (2019.9.11)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl) (2.8)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl) (1.25.11)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl) (3.0.4)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from click>=5.1->flask>=1.1.1->visualdl) (4.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl) (2.0.1)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->visualdl) (56.2.0)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->click>=5.1->flask>=1.1.1->visualdl) (3.8.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->click>=5.1->flask>=1.1.1->visualdl) (4.7.1)\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#首先需要安装最新版本的visualdl\n",
    "!pip install visualdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8989685c-b4ff-4c41-8b97-d7a880a0b3e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:11.429046Z",
     "iopub.status.busy": "2023-12-04T02:33:11.428335Z",
     "iopub.status.idle": "2023-12-04T02:33:11.434847Z",
     "shell.execute_reply": "2023-12-04T02:33:11.434069Z",
     "shell.execute_reply.started": "2023-12-04T02:33:11.429009Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reference_distribution_np(batch_size, seq_length, max_val) -> np.ndarray:\n",
    "    \"\"\" Returns a batch of inputs sampled from the reference distribution, i.e.\n",
    "    from the random uniform distribution. \"\"\"\n",
    "    return np.random.uniform(size=[batch_size, seq_length], low=0, high=max_val)\n",
    "\n",
    "#产生从0到max_val的随机数，类型为paddle.Tensor,大小为[batch_size, seq_length]，其中floor为向下取整\n",
    "def reference_distribution_paddle(batch_size, seq_length, max_val) -> paddle.Tensor:\n",
    "    #return fluid.layers.uniform_random(shape=[batch_size, seq_length], min=0, max=max_val).floor()\n",
    "    return fluid.layers.uniform_random(shape=[batch_size, seq_length], min=0, max=max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923530dc-e339-463a-8828-ef3894d6d342",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:11.436208Z",
     "iopub.status.busy": "2023-12-04T02:33:11.435859Z",
     "iopub.status.idle": "2023-12-04T02:33:11.442541Z",
     "shell.execute_reply": "2023-12-04T02:33:11.441818Z",
     "shell.execute_reply.started": "2023-12-04T02:33:11.436178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, real, fake, batchsize):\n",
    "    t = paddle.uniform((batchsize,1,1))\n",
    "    t = paddle.expand_as(t, real)\n",
    "    inter = t * real +  (1-t) * fake\n",
    "    inter.stop_gradient = False\n",
    "    inter_ = discriminator(inter)\n",
    "    grads = paddle.grad(inter_, [inter])[0]\n",
    "    grads = paddle.reshape(grads, [batchsize, grads.shape[1], grads.shape[2]])\n",
    "    epsilon = 1e-12\n",
    "    norm = paddle.sqrt(\n",
    "        paddle.mean(paddle.square(grads), axis=1) + epsilon\n",
    "    )\n",
    "    gp = paddle.mean((norm - 1)**2) * 10\n",
    "\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8b4f10-91b5-4e94-842d-bfee6d8195fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:11.443901Z",
     "iopub.status.busy": "2023-12-04T02:33:11.443559Z",
     "iopub.status.idle": "2023-12-04T02:33:11.456129Z",
     "shell.execute_reply": "2023-12-04T02:33:11.455455Z",
     "shell.execute_reply.started": "2023-12-04T02:33:11.443876Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#参数初始化的模块\n",
    "@paddle.no_grad()\n",
    "def normal_(x, mean=0., std=1.):\n",
    "    temp_value = paddle.normal(mean, std, shape=x.shape)\n",
    "    x.set_value(temp_value)\n",
    "    return x\n",
    "\n",
    "@paddle.no_grad()\n",
    "def uniform_(x, a=-1., b=1.):\n",
    "    temp_value = paddle.uniform(min=a, max=b, shape=x.shape)\n",
    "    x.set_value(temp_value)\n",
    "    return x\n",
    "\n",
    "@paddle.no_grad()\n",
    "def constant_(x, value):\n",
    "    temp_value = paddle.full(x.shape, value, x.dtype)\n",
    "    x.set_value(temp_value)\n",
    "    return x\n",
    "\n",
    "def weights_init1(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(classname)\n",
    "    if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "        normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        normal_(m.weight, 0.,1.2)\n",
    "        constant_(m.bias, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        uniform_(m.weight, -2., 2.)\n",
    "        #constant_(m.bias, 0)\n",
    "        uniform_(m.bias, -1.,1.)\n",
    "\n",
    "\n",
    "def weights_init2(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(classname)\n",
    "    if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "        normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        normal_(m.weight, 1.0, 0.02)\n",
    "        constant_(m.bias, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        uniform_(m.weight, -1, 1.)\n",
    "        constant_(m.bias, 0)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    print(classname)\n",
    "    if hasattr(m, 'weight') and classname.find('Conv') != -1:\n",
    "        normal_(m.weight, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        normal_(m.weight, 1.0, 0.02)\n",
    "        constant_(m.bias, 0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        uniform_(m.weight, -1, 1.)\n",
    "        constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ca610f-41d7-4195-984e-82c0f9685a68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:11.457599Z",
     "iopub.status.busy": "2023-12-04T02:33:11.457284Z",
     "iopub.status.idle": "2023-12-04T02:33:13.213417Z",
     "shell.execute_reply": "2023-12-04T02:33:13.212494Z",
     "shell.execute_reply.started": "2023-12-04T02:33:11.457572Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1204 10:33:11.466737  8670 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.2\r\n",
      "W1204 10:33:11.471947  8670 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear\r\n",
      "ReLU\r\n",
      "Linear\r\n",
      "ReLU\r\n",
      "Linear\r\n",
      "ReLU\r\n",
      "Linear\r\n",
      "ReLU\r\n",
      "Linear\r\n",
      "ReLU\r\n",
      "Linear\r\n",
      "Mod\r\n",
      "Sequential\r\n",
      "GeluGenerator\r\n",
      "GeluGenerator(\r\n",
      "  (gen): Sequential(\r\n",
      "    (0): Linear(in_features=32, out_features=128, dtype=float32)\r\n",
      "    (1): ReLU()\r\n",
      "    (2): Linear(in_features=128, out_features=256, dtype=float32)\r\n",
      "    (3): ReLU()\r\n",
      "    (4): Linear(in_features=256, out_features=512, dtype=float32)\r\n",
      "    (5): ReLU()\r\n",
      "    (6): Linear(in_features=512, out_features=1024, dtype=float32)\r\n",
      "    (7): ReLU()\r\n",
      "    (8): Linear(in_features=1024, out_features=512, dtype=float32)\r\n",
      "    (9): ReLU()\r\n",
      "    (10): Linear(in_features=512, out_features=256, dtype=float32)\r\n",
      "    (11): Mod(max_val=256.0,name=)\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    }
   ],
   "source": [
    "from util import mylayer\n",
    "# Generator Code\n",
    "'''\n",
    "# Generator Code\n",
    "class BigGeluGenerator(nn.Layer):\n",
    "    def __init__(self, ):\n",
    "        super(BigGeluGenerator, self).__init__()\n",
    "\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "\n",
    "            #第一个input is Z,\n",
    "            nn.Linear(INPUT_SIZE,256),\n",
    "            #nn.BatchNorm(256),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            #第二个\n",
    "            nn.Linear(256,512),\n",
    "            #nn.BatchNorm(500),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(512,1024),\n",
    "            #nn.BatchNorm(1000),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(1024,2048),\n",
    "            #nn.BatchNorm(2000),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            nn.Linear(2048,4096),\n",
    "            #nn.BatchNorm(4000),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(4096,2048),\n",
    "            #nn.BatchNorm(2500),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(2048,512),\n",
    "            #nn.BatchNorm(800),\n",
    "            nn.GELU(),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "            #第四个\n",
    "            nn.Linear(512,OUTPUT_SIZE),\n",
    "            #nn.BatchNorm(OUTPUT_SIZE),\n",
    "            mylayer.Mod(),\n",
    "            #nn.BatchNorm(OUTPUT_SIZE),\n",
    "            #mylayer.SoftSign128(),\n",
    "            #mylayer.Tanh128(),\n",
    "            #mylayer.Sigmoid256(),\n",
    "            #nn.LayerNorm(OUTPUT_SIZE),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        print(x)\n",
    "        \n",
    "        x = self.gen(x)\n",
    "\n",
    "        print(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "netG = BigGeluGenerator()\n",
    "\n",
    "'''\n",
    "# Generator Code\n",
    "class GeluGenerator(nn.Layer):\n",
    "    def __init__(self, ):\n",
    "        super(GeluGenerator, self).__init__()\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "\n",
    "            #第一个input is Z,\n",
    "            nn.Linear(INPUT_SIZE,128),\n",
    "            #nn.BatchNorm(100),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #第二个\n",
    "            nn.Linear(128,256),\n",
    "            #nn.BatchNorm(200),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(256,512),\n",
    "            #nn.BatchNorm(400),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(512,1024),\n",
    "            #nn.BatchNorm(400),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(1024,512),\n",
    "            #nn.BatchNorm(400),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #第四个\n",
    "            nn.Linear(512,OUTPUT_SIZE),\n",
    "            #nn.BatchNorm(OUTPUT_SIZE),\n",
    "            mylayer.Mod(),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.gen(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "#netG = SELUGenerator()\n",
    "#netG = Generator256()\n",
    "netG = GeluGenerator()\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba7d9ef8-bcaf-4396-8bfa-6112fdb803a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:13.214979Z",
     "iopub.status.busy": "2023-12-04T02:33:13.214568Z",
     "iopub.status.idle": "2023-12-04T02:33:13.751730Z",
     "shell.execute_reply": "2023-12-04T02:33:13.750867Z",
     "shell.execute_reply.started": "2023-12-04T02:33:13.214951Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1024, 32], dtype=float32, place=Place(gpu:0), stop_gradient=True,\r\n",
      "       [[26.16350937 , 131.25456238, 37.71149445 , ..., 148.56259155,\r\n",
      "         2.84108591  , 239.83857727],\r\n",
      "        [61.13263321 , 228.86427307, 76.50019836 , ..., 84.59951019 ,\r\n",
      "         21.86028671 , 10.44218159 ],\r\n",
      "        [56.79540253 , 123.99736023, 217.20736694, ..., 219.81364441,\r\n",
      "         51.49184418 , 70.88102722 ],\r\n",
      "        ...,\r\n",
      "        [198.68849182, 100.81215668, 34.93161011 , ..., 13.34265518 ,\r\n",
      "         8.37232399  , 125.64051056],\r\n",
      "        [107.50849152, 88.80255890 , 53.48756027 , ..., 102.76641846,\r\n",
      "         120.09224701, 142.50074768],\r\n",
      "        [16.27554893 , 216.37310791, 32.55152893 , ..., 148.78871155,\r\n",
      "         185.09587097, 16.28174973 ]])\r\n",
      "Tensor(shape=[1024, 256], dtype=float32, place=Place(gpu:0), stop_gradient=True,\r\n",
      "       [[148., 58. , 176., ..., 4.  , 44. , 96. ],\r\n",
      "        [56. , 199., 220., ..., 244., 12. , 144.],\r\n",
      "        [154., 148., 176., ..., 216., 68. , 4.  ],\r\n",
      "        ...,\r\n",
      "        [12. , 18. , 43. , ..., 16. , 252., 108.],\r\n",
      "        [6.  , 124., 52. , ..., 34. , 208., 28. ],\r\n",
      "        [88. , 216., 208., ..., 240., 222., 160.]])\r\n",
      "均值： 127.354614\r\n",
      "方差： 5470.8433\r\n"
     ]
    }
   ],
   "source": [
    "seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\n",
    "\n",
    "print(seed_noise)\n",
    "            #fake_sample = netG(seed_noise).floor()\n",
    "fake_sample = netG(seed_noise)\n",
    "print(fake_sample)\n",
    "\n",
    "arr = fake_sample.numpy()\n",
    "mean = np.mean(arr)\n",
    "print(\"均值：\", mean)\n",
    "\n",
    "# 计算方差\n",
    "variance = np.var(arr)\n",
    "print(\"方差：\", variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65a36651-5f50-432f-a592-57ccc1979605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:13.753359Z",
     "iopub.status.busy": "2023-12-04T02:33:13.752939Z",
     "iopub.status.idle": "2023-12-04T02:33:13.770083Z",
     "shell.execute_reply": "2023-12-04T02:33:13.769344Z",
     "shell.execute_reply.started": "2023-12-04T02:33:13.753331Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1D\r\n",
      "LeakyReLU\r\n",
      "Conv1D\r\n",
      "LeakyReLU\r\n",
      "Conv1D\r\n",
      "LeakyReLU\r\n",
      "Conv1D\r\n",
      "LeakyReLU\r\n",
      "MaxPool1D\r\n",
      "Flatten\r\n",
      "Linear\r\n",
      "Linear\r\n",
      "Sigmoid\r\n",
      "Sequential\r\n",
      "Discriminator\r\n",
      "Discriminator(\r\n",
      "  (dis): Sequential(\r\n",
      "    (0): Conv1D(1, 4, kernel_size=[2], data_format=NCL)\r\n",
      "    (1): LeakyReLU(negative_slope=0.01)\r\n",
      "    (2): Conv1D(4, 4, kernel_size=[2], data_format=NCL)\r\n",
      "    (3): LeakyReLU(negative_slope=0.01)\r\n",
      "    (4): Conv1D(4, 4, kernel_size=[2], data_format=NCL)\r\n",
      "    (5): LeakyReLU(negative_slope=0.01)\r\n",
      "    (6): Conv1D(4, 4, kernel_size=[2], data_format=NCL)\r\n",
      "    (7): LeakyReLU(negative_slope=0.01)\r\n",
      "    (8): MaxPool1D(kernel_size=2, stride=1, padding=0)\r\n",
      "    (9): Flatten()\r\n",
      "    (10): Linear(in_features=1004, out_features=4, dtype=float32)\r\n",
      "    (11): Linear(in_features=4, out_features=1, dtype=float32)\r\n",
      "    (12): Sigmoid()\r\n",
      "  )\r\n",
      ")\r\n"
     ]
    }
   ],
   "source": [
    "# Generator Code\n",
    "'''\n",
    "class Discriminator(nn.Layer):\n",
    "    def __init__(self, ):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "\n",
    "        self.gen = nn.Sequential(\n",
    "\n",
    "            #第一个input is Z,\n",
    "            nn.Linear(OUTPUT_SIZE,256),\n",
    "            #nn.BatchNorm(100),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #第二个\n",
    "            nn.Linear(256,512),\n",
    "            #nn.BatchNorm(200),\n",
    "            nn.ReLU(),\n",
    "\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(512,1024),\n",
    "            #nn.BatchNorm(400),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #第三个\n",
    "            nn.Linear(1024,512),\n",
    "            #nn.BatchNorm(400),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #第四个\n",
    "            nn.Linear(512,1),\n",
    "            #nn.BatchNorm(1),\n",
    "            nn.Sigmoid(),\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.gen(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "'''\n",
    "class Discriminator(nn.Layer):\n",
    "    def __init__(self,):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "\n",
    "            #第一个conv1d\n",
    "            nn.Conv1D(1,4,2),\n",
    "            nn.LeakyReLU(),\n",
    "            #第二个conv1d\n",
    "            nn.Conv1D(4,4,2),\n",
    "            nn.LeakyReLU(),\n",
    "            #第三个conv1d\n",
    "            nn.Conv1D(4,4,2),\n",
    "            nn.LeakyReLU(),\n",
    "            #第四个conv1d\n",
    "            nn.Conv1D(4,4,2),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            #池化层\n",
    "            nn.MaxPool1D(2,1),\n",
    "\n",
    "            #拉平\n",
    "            nn.Flatten(),\n",
    "\n",
    "            #第1个全连接层\n",
    "            nn.Linear(1004,4),\n",
    "            #nn.LeakyReLU(),\n",
    "\n",
    "            #第2个全连接层\n",
    "            nn.Linear(4,1),\n",
    "            nn.Sigmoid(),\n",
    "            #nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dis(x)\n",
    "\n",
    "netD = Discriminator()\n",
    "netD.apply(weights_init)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca68ce6a-5a19-43fa-9cbd-d1bfcacf8506",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:13.773410Z",
     "iopub.status.busy": "2023-12-04T02:33:13.773042Z",
     "iopub.status.idle": "2023-12-04T02:33:13.778961Z",
     "shell.execute_reply": "2023-12-04T02:33:13.778238Z",
     "shell.execute_reply.started": "2023-12-04T02:33:13.773385Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Initialize BCELoss function\n",
    "# 这里为需要改变的地方\n",
    "loss = nn.BCELoss()   # DCGAN\n",
    "#loss=nn.MSELoss()       # LSGAN\n",
    "#  the progression of the generator\n",
    "seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL) #用来产生随机数的seed，一开始的短随机数\n",
    "#print(seed_noise)\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.Adam(parameters=netD.parameters(), learning_rate=0.0001, beta1=0.9999, beta2=0.9999)\n",
    "optimizerG = optim.Adam(parameters=netG.parameters(), learning_rate=0.0001, beta1=0.9999, beta2=0.9999)\n",
    "#optimizerD = optim.Adam(parameters=netD.parameters(), learning_rate=0.001, beta1=0.9999, beta2=0.9999)\n",
    "#optimizerG = optim.Adam(parameters=netG.parameters(), learning_rate=0.001, beta1=0.9999, beta2=0.9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfeeadf5-68d6-4b7a-9240-d9be8d8f9ccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:13.780254Z",
     "iopub.status.busy": "2023-12-04T02:33:13.779924Z",
     "iopub.status.idle": "2023-12-04T02:33:14.019665Z",
     "shell.execute_reply": "2023-12-04T02:33:14.013194Z",
     "shell.execute_reply.started": "2023-12-04T02:33:13.780230Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from visualdl import LogWriter\n",
    "Dwriter = LogWriter(logdir='/home/aistudio/visualdl/dvisual')  #判别器可视化路径\n",
    "Gwriter = LogWriter(logdir='/home/aistudio/visualdl/gvisual')  #生成器可视化路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55bca612-c32c-46fa-aacf-6ae7702fee37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:14.023381Z",
     "iopub.status.busy": "2023-12-04T02:33:14.022946Z",
     "iopub.status.idle": "2023-12-04T02:33:14.032716Z",
     "shell.execute_reply": "2023-12-04T02:33:14.031965Z",
     "shell.execute_reply.started": "2023-12-04T02:33:14.023335Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nADV_MUL = 1\\ndef train(outparmfile,STEPS):\\n    losses = [[], []]\\n    #plt.ion()\\n    now = 0\\n    for pass_id in range(STEPS):\\n        ############################\\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\\n        ###########################\\n\\n        #errD = 0.\\n        for i in range(ADV_MUL):\\n            \\n            optimizerD.clear_grad()\\n\\n            real_sample = reference_distribution_paddle(BATCH_SIZE, OUTPUT_SIZE, MAX_VAL)\\n            #if pass_id %100 ==0:\\n                #print(\"real_sample\",real_sample.numpy()[0])\\n            label = paddle.full((BATCH_SIZE, 1), real_label, dtype=\\'float32\\')\\n            real_sample = paddle.reshape(real_sample, [BATCH_SIZE,1,OUTPUT_SIZE])\\n            real_out = netD(real_sample)\\n\\n            real_loss =  -1 * paddle.mean(real_out)\\n            #errD_real.backward()\\n\\n\\n            seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\\n            #fake_sample = netG(seed_noise).floor()\\n            fake_sample = netG(seed_noise)\\n\\n\\n            if pass_id %100 ==0:\\n                print(\"fake\",fake_sample.numpy()[0].astype(int))\\n            #label = paddle.full((BATCH_SIZE, 1), fake_label, dtype=\\'float32\\')\\n\\n\\n            fake_sample = paddle.reshape(fake_sample, [BATCH_SIZE,1,OUTPUT_SIZE])\\n            fake_out = netD(fake_sample.detach())\\n            fake_loss = paddle.mean(fake_out)\\n\\n            gp = gradient_penalty(netD, real_sample, fake_sample, real_sample.shape[0])\\n            d_loss = fake_loss + real_loss + gp \\n\\n            #print(\"fake_loss\",fake_loss.numpy(),\"real_loss\",real_loss.numpy(),\"gp\",gp.numpy())\\n\\n\\n            d_loss.backward()\\n            optimizerD.step()\\n            optimizerD.clear_grad()\\n\\n            if i== ADV_MUL-1:\\n            #    d_loss = fake_loss + real_loss\\n                if pass_id %100 ==0:\\n                    print(fake_loss.numpy()[0],real_loss.numpy()[0])\\n\\n        #print(errD.numpy()[0])    \\n        losses[0].append(d_loss.numpy()[0])\\n\\n        ############################\\n        # (2) Update G network: maximize log(D(G(z)))\\n        ###########################\\n\\n        optimizerG.clear_grad()\\n        seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\\n        #fake = netG(seed_noise).floor()\\n        fake = netG(seed_noise)\\n\\n        #label = paddle.full((BATCH_SIZE, 1), real_label, dtype=\\'float32\\')\\n        fake = paddle.reshape(fake, [BATCH_SIZE,1,OUTPUT_SIZE])\\n        output = netD(fake)\\n\\n        g_loss = -1*paddle.mean(output)\\n        g_loss.backward()\\n        optimizerG.step()\\n        optimizerG.clear_grad()\\n\\n        losses[1].append(g_loss.numpy()[0])\\n\\n\\n\\n\\n        ############################\\n        # visualize\\n        ###########################\\n\\n        now += 1\\n\\n        #日志中增加损失\\n        Dwriter.add_scalar(tag=\"train/loss\", step=now, value=d_loss.numpy()[0])\\n        Gwriter.add_scalar(tag=\"train/loss\", step=now, value=g_loss.numpy()[0])\\n\\n        \\n        if pass_id %100 ==0:\\n            msg = \\'Epoch ID={0} \\n\\n D-Loss={1} G-Loss={2}\\'.format(pass_id, d_loss.numpy()[0], g_loss.numpy()[0])\\n            print(msg)\\n\\n\\n    paddle.save(netG.state_dict(),outparmfile)\\n\\n    file_paths = [\\'lossfile1.txt\\', \\'lossfile2.txt\\']\\n    for i in range(len(loss)):\\n        data = loss[i]\\n        file_path = file_paths[i]\\n\\n        # 将数据按行组合成字符串\\n        content = \\'\\n\\'.join(data)\\n\\n        # 将数据写入txt文件\\n        with open(file_path, \\'w\\') as file:\\n            file.write(content)\\n\\n        print(f\"Data has been written to the file: {file_path}\")\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练\n",
    "'''\n",
    "ADV_MUL = 1\n",
    "def train(outparmfile,STEPS):\n",
    "    losses = [[], []]\n",
    "    #plt.ion()\n",
    "    now = 0\n",
    "    for pass_id in range(STEPS):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        #errD = 0.\n",
    "        for i in range(ADV_MUL):\n",
    "            \n",
    "            optimizerD.clear_grad()\n",
    "\n",
    "            real_sample = reference_distribution_paddle(BATCH_SIZE, OUTPUT_SIZE, MAX_VAL)\n",
    "            #if pass_id %100 ==0:\n",
    "                #print(\"real_sample\",real_sample.numpy()[0])\n",
    "            label = paddle.full((BATCH_SIZE, 1), real_label, dtype='float32')\n",
    "            real_sample = paddle.reshape(real_sample, [BATCH_SIZE,1,OUTPUT_SIZE])\n",
    "            real_out = netD(real_sample)\n",
    "\n",
    "            real_loss =  -1 * paddle.mean(real_out)\n",
    "            #errD_real.backward()\n",
    "\n",
    "\n",
    "            seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\n",
    "            #fake_sample = netG(seed_noise).floor()\n",
    "            fake_sample = netG(seed_noise)\n",
    "\n",
    "\n",
    "            if pass_id %100 ==0:\n",
    "                print(\"fake\",fake_sample.numpy()[0].astype(int))\n",
    "            #label = paddle.full((BATCH_SIZE, 1), fake_label, dtype='float32')\n",
    "\n",
    "\n",
    "            fake_sample = paddle.reshape(fake_sample, [BATCH_SIZE,1,OUTPUT_SIZE])\n",
    "            fake_out = netD(fake_sample.detach())\n",
    "            fake_loss = paddle.mean(fake_out)\n",
    "\n",
    "            gp = gradient_penalty(netD, real_sample, fake_sample, real_sample.shape[0])\n",
    "            d_loss = fake_loss + real_loss + gp \n",
    "\n",
    "            #print(\"fake_loss\",fake_loss.numpy(),\"real_loss\",real_loss.numpy(),\"gp\",gp.numpy())\n",
    "\n",
    "\n",
    "            d_loss.backward()\n",
    "            optimizerD.step()\n",
    "            optimizerD.clear_grad()\n",
    "\n",
    "            if i== ADV_MUL-1:\n",
    "            #    d_loss = fake_loss + real_loss\n",
    "                if pass_id %100 ==0:\n",
    "                    print(fake_loss.numpy()[0],real_loss.numpy()[0])\n",
    "\n",
    "        #print(errD.numpy()[0])    \n",
    "        losses[0].append(d_loss.numpy()[0])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        optimizerG.clear_grad()\n",
    "        seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\n",
    "        #fake = netG(seed_noise).floor()\n",
    "        fake = netG(seed_noise)\n",
    "\n",
    "        #label = paddle.full((BATCH_SIZE, 1), real_label, dtype='float32')\n",
    "        fake = paddle.reshape(fake, [BATCH_SIZE,1,OUTPUT_SIZE])\n",
    "        output = netD(fake)\n",
    "\n",
    "        g_loss = -1*paddle.mean(output)\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "        optimizerG.clear_grad()\n",
    "\n",
    "        losses[1].append(g_loss.numpy()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ############################\n",
    "        # visualize\n",
    "        ###########################\n",
    "\n",
    "        now += 1\n",
    "\n",
    "        #日志中增加损失\n",
    "        Dwriter.add_scalar(tag=\"train/loss\", step=now, value=d_loss.numpy()[0])\n",
    "        Gwriter.add_scalar(tag=\"train/loss\", step=now, value=g_loss.numpy()[0])\n",
    "\n",
    "        \n",
    "        if pass_id %100 ==0:\n",
    "            msg = 'Epoch ID={0} \\n\\n D-Loss={1} G-Loss={2}'.format(pass_id, d_loss.numpy()[0], g_loss.numpy()[0])\n",
    "            print(msg)\n",
    "\n",
    "\n",
    "    paddle.save(netG.state_dict(),outparmfile)\n",
    "\n",
    "    file_paths = ['lossfile1.txt', 'lossfile2.txt']\n",
    "    for i in range(len(loss)):\n",
    "        data = loss[i]\n",
    "        file_path = file_paths[i]\n",
    "\n",
    "        # 将数据按行组合成字符串\n",
    "        content = '\\n'.join(data)\n",
    "\n",
    "        # 将数据写入txt文件\n",
    "        with open(file_path, 'w') as file:\n",
    "            file.write(content)\n",
    "\n",
    "        print(f\"Data has been written to the file: {file_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c3a0ac2-2d93-4262-bfcd-33e4fdf743e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:14.034406Z",
     "iopub.status.busy": "2023-12-04T02:33:14.033975Z",
     "iopub.status.idle": "2023-12-04T02:33:14.047288Z",
     "shell.execute_reply": "2023-12-04T02:33:14.046516Z",
     "shell.execute_reply.started": "2023-12-04T02:33:14.034376Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "ADV_MUL = 1\n",
    "GEN_MUL = 1\n",
    "\n",
    "#训练\n",
    "def train(outparmfile,STEPS):\n",
    "    losses = [[], []]\n",
    "    #plt.ion()\n",
    "    now = 0\n",
    "    for pass_id in range(STEPS):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        #errD = 0.\n",
    "        for i in range(ADV_MUL):\n",
    "            \n",
    "            optimizerD.clear_grad()\n",
    "\n",
    "            real_sample = reference_distribution_paddle(BATCH_SIZE, OUTPUT_SIZE, MAX_VAL)\n",
    "            #if pass_id %100 ==0:\n",
    "                #print(\"real_sample\",real_sample.numpy()[0])\n",
    "            label = paddle.full((BATCH_SIZE, 1), real_label, dtype='float32')\n",
    "            real_sample = paddle.reshape(real_sample, [BATCH_SIZE,1,OUTPUT_SIZE])\n",
    "            real_out = netD(real_sample)\n",
    "            errD_real = loss(real_out, label)\n",
    "            errD_real.backward()\n",
    "\n",
    "\n",
    "            seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\n",
    "            #fake_sample = netG(seed_noise).floor()\n",
    "            fake_sample = netG(seed_noise)\n",
    "            if pass_id %100 ==0:\n",
    "                print(fake_sample.numpy()[0].astype(int))\n",
    "            label = paddle.full((BATCH_SIZE, 1), fake_label, dtype='float32')\n",
    "            fake_sample = paddle.reshape(fake_sample, [BATCH_SIZE,1,OUTPUT_SIZE])\n",
    "            fake_out = netD(fake_sample.detach())\n",
    "            errD_fake = loss(fake_out,label)\n",
    "            errD_fake.backward()\n",
    "            optimizerD.step()\n",
    "            optimizerD.clear_grad()\n",
    "\n",
    "            if i== ADV_MUL-1:\n",
    "                errD = errD_real + errD_fake\n",
    "                #if pass_id %100 ==0:\n",
    "                    #print(errD_real.numpy()[0],errD_fake.numpy()[0])\n",
    "\n",
    "        #print(errD.numpy()[0])    \n",
    "        losses[0].append(errD.numpy()[0])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        optimizerG.clear_grad()\n",
    "        seed_noise = reference_distribution_paddle(BATCH_SIZE, INPUT_SIZE, MAX_VAL)\n",
    "        #fake = netG(seed_noise).floor()\n",
    "        fake = netG(seed_noise)\n",
    "        label = paddle.full((BATCH_SIZE, 1), real_label, dtype='float32')\n",
    "        fake = paddle.reshape(fake, [BATCH_SIZE,1,OUTPUT_SIZE])\n",
    "        output = netD(fake)\n",
    "        errG = loss(output,label)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        optimizerG.clear_grad()\n",
    "\n",
    "        losses[1].append(errG.numpy()[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ############################\n",
    "        # visualize\n",
    "        ###########################\n",
    "\n",
    "        now += 1\n",
    "\n",
    "        #日志中增加损失\n",
    "        Dwriter.add_scalar(tag=\"train/loss\", step=now, value=errD.numpy()[0])\n",
    "        Gwriter.add_scalar(tag=\"train/loss\", step=now, value=errG.numpy()[0])\n",
    "\n",
    "        \n",
    "        if pass_id %100 ==0:\n",
    "            msg = 'Epoch ID={0} \\n\\n D-Loss={1} G-Loss={2}'.format(pass_id, errD.numpy()[0], errG.numpy()[0])\n",
    "            print(msg)\n",
    "\n",
    "\n",
    "    paddle.save(netG.state_dict(),outparmfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4746df4-e036-4dfd-b30c-de20581da16a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-04T02:33:14.048778Z",
     "iopub.status.busy": "2023-12-04T02:33:14.048426Z",
     "iopub.status.idle": "2023-12-04T02:44:58.559352Z",
     "shell.execute_reply": "2023-12-04T02:44:58.558422Z",
     "shell.execute_reply.started": "2023-12-04T02:33:14.048751Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 140 137 151 251  12 136 254  71  26  56 150 240  92 208 108 119  50 228\r\n",
      " 248 143 116 206 185 154 137 244 113   3 186 142   5   0 218 209 218  62\r\n",
      " 224 248  41 249  50 161 206 206 228  24 129 143  41 186 147 136  35  38\r\n",
      "  40  77   4 148 250 229 188  13  30 124  26  85  64   6  21  98  21 104\r\n",
      "  10 102  76 196 188 196  84 105 190   7 224 214 214  70  60  76 106 114\r\n",
      " 200  84 254 113]\r\n",
      "Epoch ID=44400 \r\n",
      "\r\n",
      " D-Loss=0.4919443428516388 G-Loss=7.24340295791626\r\n",
      "[128 126 170 174 146  17  38  52 154 174 253 148  26 136  48 169 212 251\r\n",
      " 106 214 157 168 200 160 236  71 149 111 253  94  12 176  20 246   5  13\r\n",
      " 227  30  33   6 106  12  78  98  76  98 152 106 141 222 234 226 170 128\r\n",
      " 234 146  85 190  44  12  48 212 145  80  18 116 126 151 169 136   6  96\r\n",
      " 163 208  66  40  98 134 239 216 128  86 243  21 129  98  63  14 238 102\r\n",
      " 189   4 219  84 106 114   4 157  13  19  44 186  67  76 240 187 176  10\r\n",
      "  73 188 205 236  30 249 248 174  96 206   4 160 224 110  65  20  96 152\r\n",
      " 141 167  16 121  77 188  57  38 242 208  92  36 216 168 118 236 114  36\r\n",
      " 194 124 207  36  64 156 252  42  80 104 114  71 236 118  68 136 123  20\r\n",
      " 111  55  28 133  60 107  59  64 156 200 156 131  38 236 136 146  95  14\r\n",
      " 166 144  40 125  69 142  58   0 171 139 166  39  63 100  82 164 150  79\r\n",
      " 207 141 255  64 191  45  41  91  88  94 111 196  53 238  52 245 137 222\r\n",
      " 159 162 198  68 164 136   8  18 156 184  28 215 209  84 226 194  34 175\r\n",
      "  10  44  83  92 136 160 224  96 242  54  92 162  69  75 112 194 189 170\r\n",
      " 248  19 208 104]\r\n",
      "Epoch ID=44500 \r\n",
      "\r\n",
      " D-Loss=0.5029885172843933 G-Loss=10.390971183776855\r\n",
      "[220  80  16 187 179 250 125 131 180 211 157  60 103 242 172  96 140  71\r\n",
      "  52 232 131 149  99  29 113  62 119  64  38 104 138 117 156 218 204 197\r\n",
      " 134  70  14 166 120 126 154 170  92 154 196 224  55 108 184 100 149 114\r\n",
      "  69 148  57 118  17 204  34 192 188 112  36 182 220 253  17 150 112 116\r\n",
      " 167 216 136 147 232  95 121   8  20   0 234 165 210 221 184  34 120 200\r\n",
      " 121 139 134 238 216  94 248 170 155 124  80 138 142 151 188  46  90  65\r\n",
      " 226 164 182 210  13 243  84  10 106 217  57  66  79  39  17 200 147 250\r\n",
      " 190 225 108 179  27 174 196 152  48 114  74  36  76 156 164  68 101 129\r\n",
      " 192  24 115 192 240 198 181  12  80  85  68 147   7 164 224 146 114 180\r\n",
      " 210  78 200 201 236  26 154  96  17 120  94 108 122  24 188  80 117 168\r\n",
      " 235 140 188  70 244  78 168 254   0 100  16 206 165  74 245 236 136 185\r\n",
      "  40  52  76  15 180  57 120 166 200  70  67 177  71 248 162 128 202 144\r\n",
      " 148 214 204 111 150  74 166 196 140 230  40  74 132 104  54 155  75 250\r\n",
      " 188 184 207 148 188 119 184 104 187  26 180 200  24 172 240 252 184  40\r\n",
      "  11   4  54 120]\r\n",
      "Epoch ID=44600 \r\n",
      "\r\n",
      " D-Loss=0.49454718828201294 G-Loss=7.486167907714844\r\n",
      "[104  12  84  16  11 108  70  18 244  11  55 204  31  79  84  87  52  30\r\n",
      " 112 156 127 111 167 127  38  22 228  48  49 217 165  80 158 132 200 142\r\n",
      "   6 108 107 212 240 235 100 238 158 162 224 190 240 202  10 196  56 184\r\n",
      "  70 112  82  64 106 131 170 234 180 200 112   4  24  69  28  64 152 200\r\n",
      " 145 152  91  72 134 160  23 130 192  40  49  82 155  18 216  59  70 208\r\n",
      "  62 174 218 121 122  56 208 244  18  45 128  47 180 170 195  18 164 155\r\n",
      " 237 232  81 240 130 105 250  86  92 112 244  16 108 186 205 137   6 202\r\n",
      "  56 144  80  14 218  54  30   1 136 214 196 138 164 190 150 180 172 156\r\n",
      " 182  40 198 150 157 184 204 228 191 232 148 208 188 160  94  40 243  80\r\n",
      " 150 236  84 106 232 116  12  14 240 140  69 216 122 192  36 140  28 169\r\n",
      " 253 244 188 121 164 192  68   4   8 131 184 133 199  16 104 208 158 112\r\n",
      "  78 240 160 255 136 108 200  72 216  26 136 218  16 168  37  69  84  34\r\n",
      " 134  73 100 238 232 129   8  10 196  30 160 168 136 242  34   6 114  68\r\n",
      "  88   0 206  86 240  50 214 134 152 214 216 164  48 118 104  66  36 152\r\n",
      " 216 206  86 186]\r\n",
      "Epoch ID=44700 \r\n",
      "\r\n",
      " D-Loss=0.48392361402511597 G-Loss=9.76085090637207\r\n",
      "[132 138  21 240  40  36 128  77  88  42  37 108  72  39 141 186 252  52\r\n",
      "   0 182  52 203  87 124 131 192 220 246  52 124  68 250 152 216 193  72\r\n",
      " 116  76 219 240 100  16  40 105  28 181   0 236  44 179 190 193  65 144\r\n",
      "  91 114 187  44 160  59 200  56 100 202  46 190  88  34 109 125 165 164\r\n",
      "  21 140  84   3 220 136  71  24  20 237  78 224 107  75   4 255 102 108\r\n",
      " 138 128  81 151 115 170 192  54 103 249  24  68 117  53  63  50 184 121\r\n",
      "  86 254  89 144 238 175  82  29 190  64 104 237  24 115 172  20  13  24\r\n",
      "   6 238   0 128 181  98 187 142 164 103 118 192 148 116  98 100 112 140\r\n",
      " 176 154  49 208  52 247 238  20 133  56  14 158 109  84 158 211  87 246\r\n",
      " 118  10 242 150 214 231   9  66 248 192 146   7  40 104  48  68  56 166\r\n",
      " 221 168  24  13  70 252   9 116 201 190 132 214 176 116 195  58  85  71\r\n",
      " 148 244  77 170 235  76  52  99 110 216  85 144  18  68 238  63 212 202\r\n",
      " 129  69  56 246 144 170 230  92  50 134  90  20   9 107  99  26 163 205\r\n",
      " 208 160 101  56 244  36 218 203 138 249 136  42  28   1  90 121  90  18\r\n",
      "  52 232  36  67]\r\n",
      "Epoch ID=44800 \r\n",
      "\r\n",
      " D-Loss=0.5279828310012817 G-Loss=8.624174118041992\r\n",
      "[164 176 196  97 107  92 246 113  34  29  63  17  69 151  58 151  70   0\r\n",
      " 244  54 229  88 200 137 198  60 210 144  19 110 179 208   8  26  80  43\r\n",
      " 160 216 208  42 103 147 204  74 166  83 242 142 240 233 106  55 202 214\r\n",
      " 211 104 182 206 200 192 250  83 226 176 229 196  28  81  62  64  84  16\r\n",
      "  94 240 250  69  64  48 221 106 123 145 171  93 244 202 132 148 201  16\r\n",
      " 217 154 226 112   6  11  40 100  27  80  52 148 202  20  22  53 162 166\r\n",
      " 114 220 185 117 196  75 132 118 101  54 188 192  28 240 176  55   1  52\r\n",
      " 199 226 128 176 244 190  26 112 176  83  94 191  60 112  50  15 176 180\r\n",
      "  34 148  62 124 155  53 142 244 233   4 239 194 159  38  40 110  12 254\r\n",
      " 179  66 254 213 212 244 111 190 131  44 177   3 234 200  36 134  38 192\r\n",
      " 144 208 192 138  36  96 176 136  34 222  22  16 250  44 177 184 214 250\r\n",
      " 211 202 244  54 131  12 250  16 254 203  33  51  52  80 133  96  63  66\r\n",
      " 239  50  46 152  26 186 224  52 144  93  22  52   4 224 108 182 214  10\r\n",
      "  84 228  56  98 198 140 188 163  25 176 212  52  28 240  48 172 196  42\r\n",
      "  80 146  36  39]\r\n",
      "Epoch ID=44900 \r\n",
      "\r\n",
      " D-Loss=0.5524361729621887 G-Loss=8.529497146606445\r\n",
      "[118 198 138  51  34 223 160  26 167  47   1 246 186 118 208  98 182 160\r\n",
      " 210 191 130 100  44 187 254 134  24  98 184 116 243 130   4 170 168 141\r\n",
      "  98 194   5 114  14 135  24 238 140 224  96 118 102 112 224 110 132 146\r\n",
      " 197  30 174  13 250  24 172 102  48 102 224  60  92 170  95  62 174 118\r\n",
      " 105  48 110  48 120 148 104  52   4 186  49  90 182 205  89   6 194  82\r\n",
      "  51  53 157 238  69 212 240 198 144  79  88 234  47 139 153  73 167  58\r\n",
      " 253  88  54 238 117 111  63 187 232 176 178 132  60 195 208 187 107 222\r\n",
      " 162 252 228 169 202 139 122  68 142 121 254  20 162  80 221 112 110 144\r\n",
      " 206  36 112 116 120 214 209 220 251 146 114 136 124  62 188   2 175 244\r\n",
      "  13  77 158 177  48  60 209   9 246 110  75 181 254 164  88 219  98  76\r\n",
      " 135  82 234 217 245  84 108 158 156  59  76   0 253 122 226  76 227  92\r\n",
      " 109  56 164 131 226 151 224 219  58 200  96  48  62 232 124 143  74 196\r\n",
      " 132 203  84 106 184 182  92 238 244  51  41 199 222  24  63  52  80  64\r\n",
      " 240 224 116 252 126   5 224  61 224  77 160 232 130 193  40  87   8 103\r\n",
      " 142 220  60 143]\r\n",
      "Epoch ID=45000 \r\n",
      "\r\n",
      " D-Loss=0.521182656288147 G-Loss=9.386187553405762\r\n",
      "[ 80 180 248 204 184  48 144  74 166  62 230 150 165 208  32  14  48 139\r\n",
      " 113  36  42  94  47 168  70 107 124 126  41  80 220 124  90 132  53 115\r\n",
      " 126 110 127 176  88 236 240 184  86 232 116 160   6   1 224  70  78 250\r\n",
      " 243 190 164  19 238  82 193 194  18 216 198 112 254  68  88 156 130 152\r\n",
      " 139 100  16  63 176 163 108 232   0 160   6 120  93 182  76 149 144  72\r\n",
      " 194 146 136   6 224  34 218 211  82 200 148 222  70 236 188 202 133  26\r\n",
      " 138  80 135   4 148 194 239 189 112 184 179 119 104   1 214  84 150  33\r\n",
      "  10 238  92 148 226 202 113 167 174 229 212 248 252 248 214  87  14 188\r\n",
      " 122 244 115  91 173 176  40  72  16  20   0 162 204  67  74  58 102 168\r\n",
      " 216 192   8 231 102  42 164 238  52 172  90 119 100  64 216  30  17  56\r\n",
      " 101 164  82 177  53 138  12 187 187   7   4  93  49 194  98 162  85  79\r\n",
      " 100  99 248  18 223   8 144  92 116 154  80 123 137  96 190  19  40   3\r\n",
      " 179  24  48 211 128  13  92 177 132   5  37  54 208 167 166  12 193  58\r\n",
      "  32   0 210  74 160  88 120  77  79 238  40   6 236 218 140 109 231  52\r\n",
      "  20  21 120 156]\r\n",
      "Epoch ID=45100 \r\n",
      "\r\n",
      " D-Loss=0.5059943199157715 G-Loss=8.297685623168945\r\n",
      "[121 154  20  98  27 112 194 246  76 155 238 149 173 106  95 191 116  39\r\n",
      "  35  47 212 201 214 168  57 156  20 176  76  38 188 130  44   2 202 128\r\n",
      "  48  16  65 254  77 111  16 204  30 172 244  66  36  92 216 192 203  60\r\n",
      "  84 218 210 213  18  25 118  19  71  24 222 124  60 214  12 167  76  34\r\n",
      " 221  88  69 134 168  26 156  34  38 146 128  26 176 141 128 232 174 118\r\n",
      " 112 102 249  21 144  60 184  14  44  72 216 112 220  92  35  44 167 202\r\n",
      " 208 192 211 225 170  68  14  28  18  60 220 210 225  18 108 254 120  58\r\n",
      "  48   2  76  41 142   6  54 254 126   4  95  41  30 120   9 233  11  23\r\n",
      " 158  92 215  84 245 100 229 241  93  20 202 169  61 206  13  82   4 168\r\n",
      " 212  16 142 219 206  30 238 109  11 164 171 161  12 188 196  52  26  38\r\n",
      "  50 168  56 121  61 180 220 140  47 147 176 108 144  94 105 220 116  73\r\n",
      "  25 212 108  50 126 146 214 155 236  34 254  62 122 112 204 103  41 176\r\n",
      " 250 120  62 173  26 140  50  90 124  10 114  29 254 101 203  72  47 192\r\n",
      " 222  38 206  61 248  92   8 229 105 108   2  10 140 152  32  22  20  20\r\n",
      "  80  55 120 141]\r\n",
      "Epoch ID=45200 \r\n",
      "\r\n",
      " D-Loss=0.5291051864624023 G-Loss=10.309059143066406\r\n",
      "[208 180 108 168 255 118 208   2 252  50 158  53  84 117  48 101 242 160\r\n",
      " 214  52 253 204 152 154 176   2 206  68 253   4  20 232 156  68  77 216\r\n",
      "  82 128 206  49  84 198 190   1  80 152  20 172  32 204  16 114 193 217\r\n",
      " 254 206 178 124  24   0 222  52 186 168 166 174 104 240  85 148 120  61\r\n",
      "   0 144 242   7 208  20 150 201   3 166  74 214  73 208 242 148   8 200\r\n",
      " 194 244  72 166  96 246  60 250 134 245  84  91  44  82 201 151  70  18\r\n",
      " 156 124  90  60 252 198 215 130  60 204 139  58  36  50 238   8  96 170\r\n",
      " 108 215  32 231 236   2  54 231  40  24 136 174 140 108  80  88  24  96\r\n",
      "  90 136   6  30  12  14   3  81  80  84  10  10 164  50 143 191  64 168\r\n",
      "  18 228 198  45  60 164  83  22 124  92  69  55 142 236  44 220 236 133\r\n",
      " 208 216  74  37 124 212   8 133 140  63  60   6  63  36  32   8 144  46\r\n",
      "  37  46  93 213 208 195  44  90  28  76  90 219  92 252 187  33  40 244\r\n",
      " 216 100 168 148 212 203 104 147  66 251 151 100 246 116   8 233 212 142\r\n",
      " 226  32 135  82 164 144  16 142  55  77 136  24  20  60  32 216  52 254\r\n",
      " 116  12 244 173]\r\n",
      "Epoch ID=45300 \r\n",
      "\r\n",
      " D-Loss=0.535663902759552 G-Loss=7.193920135498047\r\n",
      "[242 126  26 179  45 254  68 184 123 250  83 143 183  60 240 250   1  71\r\n",
      " 213 204  36 180  48 145  16  35   0  59 231 177   4 233 250  44  84  20\r\n",
      " 212 184 202  76 193  36 192  52 176 207 176 196 193 196 170  60 114  41\r\n",
      " 206  54 247  70 195  93 167 144  74  80 164 160 186 195 163 196 111 138\r\n",
      "  18  72  34 144 140 108  65 106  14 157 113 195 117 190 167 221  20  24\r\n",
      " 159 217  20 196  85 241 132  17 210 222   2 125 104  85 185 196 180  75\r\n",
      " 137  68 112 150 222  49 255 129 236 226  34  56 157 235  36 120 255 179\r\n",
      " 219 144 252 240 236  74 164 228   9 129  18 126 234 152 184 147 194  60\r\n",
      " 140 234 177 198  22 236  25 250 105 133  16 106  93  72  24  93  29 224\r\n",
      " 226 148  96 190 212  85 139 239 180  28 146 182   6 130  80 168  96  10\r\n",
      "  39 192   7 131 237 120   6 211  25  38 192 211 123  54 230 100 244  52\r\n",
      "  94  74 118  93  31 160 106  67 136 148 188  38 198  36 143   4 134 107\r\n",
      "  45 130 116  94 106 116  24 231  96  66 150 180 104 162 148   1 127 230\r\n",
      " 140  80 146 106 210 224   2 212  58  72 201 244  96  56   6  54 248 246\r\n",
      " 128 210 100 202]\r\n",
      "Epoch ID=45400 \r\n",
      "\r\n",
      " D-Loss=0.504122257232666 G-Loss=10.162298202514648\r\n",
      "[ 98 180   8 213  95  84  83  44  95  97   0 224 164 147 144 232  12 124\r\n",
      " 226 154  66 167  53 218 182 150 198 166  11 112 154 179 154 134 120 127\r\n",
      "  90  78 152  38 150 145 136 177  10  68 180 190  32 147  72 241 201  52\r\n",
      "   8 193 229  49  31  41 248   5 134 248  98 192   0  77 152 136 134 149\r\n",
      " 111 200 142 221 100  29 241 160  27 152  63 140  88 152 240 220 242 160\r\n",
      "  90  80 116 210  88  64 136 221 144  16 120  43   0 126  30  31 244 173\r\n",
      " 127  28  95  18 144 220   6 240   8 228  94   8 178  62 160 220 153 236\r\n",
      " 142 103 216 210 124 154 232  65 144 136  50  60 102 172 146  56  96 186\r\n",
      "  24 244  13 195 229  34  55   2   9  36   6 230   6 172  99  77 158 122\r\n",
      "   2 231 148  37 148  66 228 158 122 112 145 124  92 248 108 236 143   2\r\n",
      " 214 114  10  75  86 155 240 148 246  18 168 170 116  56 126  28  23 129\r\n",
      " 205  99  43 134 219  44 220  12  52 120 249  44 137  84   4 181 155 242\r\n",
      " 230 212 119 203 112  80 144 229  84 184 230 252  24 156   2 105 146 126\r\n",
      " 152 234 200 208 231  56 238 170 211  36  88 216 179  24  56 200 158 148\r\n",
      "  16 249 196 250]\r\n",
      "Epoch ID=45500 \r\n",
      "\r\n",
      " D-Loss=0.5149949789047241 G-Loss=8.216744422912598\r\n",
      "[214  42  88 202  34  12 108  95 239 170 233 228 188  60  90 113 238 134\r\n",
      " 244 194 223  89 160 199 131  70  11 188   5  64 156  51  74  42 182 148\r\n",
      "  80   8 177 105 200  95 192   9 208 206 118 202 206 185 154  36  86 161\r\n",
      " 104 158  64 233 178 232 210 253  76 216  18 242  20 192 126  96  36 231\r\n",
      " 170 240   2 153  30 113 136  72 172  66 212 110  32 174  40  29 142 176\r\n",
      " 207 176 124  39 185 176  96 239 243 133 128 238  20 112 174  28 196 135\r\n",
      "  56 170  18 220  78 201  43 235  20  24  42  22 158 230  72 242  80 192\r\n",
      " 196 239 248 166 164 104 113  98  60 130 246 102   6 224  75 179  21   0\r\n",
      " 236 208 145 223 211   6  93  14  56 248 178 100  66 168 115  42  25 188\r\n",
      " 158 212 124 111  24  73 221 242 220 120  90  84 216  90  56 228 178 213\r\n",
      " 249  26 240  22 189 200 101 236 212 106   8 142 170 214 243  80  53  17\r\n",
      " 208 134 109 180 247  84 208  66 126  62  39 144 175 160 146  95  22  26\r\n",
      "  86 213  46  71 164 168 164 120  44  16  63 241  48  20  48 170  14  92\r\n",
      " 216 230 138 152 102  22  44 124  50  14 134 148 151 215 168 200 124 246\r\n",
      " 244 128 150 138]\r\n",
      "Epoch ID=45600 \r\n",
      "\r\n",
      " D-Loss=0.4623231887817383 G-Loss=10.32405948638916\r\n",
      "[ 24  28 174 152 118 156 254  20  67 241  91 236 242 180 195 163 124 127\r\n",
      " 154 233 120 160 170 195  37 244 216 252  79  17 103 242 179 182 226 113\r\n",
      " 116  70  36  88 108  57 172  89  98 110  40 188 104  16 184 193 110  76\r\n",
      "  35  46  78 108 104 220 136 104 102 112 202  18 220  32 206 120 218 185\r\n",
      " 228 202 229 169  62  19 121 156 176 219 121  69 138  58  34 164  68 194\r\n",
      " 139  32  67 222 171 111  80 146 194 157  24 176 153 240 250 169  14 147\r\n",
      "  56  54  69 115   3 134 161 123 113 184 182 160 192  80  18 202  84 178\r\n",
      " 213 179 190 231  75  80 245 200 194  87 248 146 144 248 254 154 201  68\r\n",
      " 212  96  24 108 125  70 171   4 109 146   3  76 138 148  92  52 128 230\r\n",
      "  64 122 217 167 226 100 196 162  16 184 162 168  42  46 156 140 208 101\r\n",
      "  70  34  20 126  64 180  70 244  37 124 232 163  14 228 223  83  38 254\r\n",
      " 203 216 125 222  37  65  76  61  46 100 138 170  43 116  90  22 142 158\r\n",
      "  70 157  10 243  72  74 148  94  52 120 117  70 226  45 106 236  31 156\r\n",
      "  72  72 218  86 160 186 116 235 214 185 140  34 228  15 100 126 125 114\r\n",
      " 152 144 152 220]\r\n",
      "Epoch ID=45700 \r\n",
      "\r\n",
      " D-Loss=0.5141769051551819 G-Loss=8.481805801391602\r\n",
      "[116 228  14 212 156 212  36 224 206  36 145  88  99 160 118 140  98 171\r\n",
      " 110   0 192 162  25 150 122 154  37  92 122 247  47  40  94  12 176  20\r\n",
      " 174  20 108  94 116 170  32  92 130 170 160  60 212   0 232 170 133 218\r\n",
      " 158  42 160 110  36   8 179 226 236 244 180  72 244 242  97   0  57 136\r\n",
      " 117 244 203 191 160 254  68 216 222  66 196  87 138  23  97 168  87 186\r\n",
      " 227 210  51  28 148 222  92 204 239  10  84 140 252 113 110 104 124 131\r\n",
      "  68 248 186 252 134 140 216  94 160 248 197 135 206  30 162 150 116 102\r\n",
      "   4 199 120 106 158  21   9  56  94  37  49 117  86 152 242 205  45 196\r\n",
      " 125 190  16 112  42  98 168  14  74 154 152 120 148  16  67 158 148 104\r\n",
      " 161  66 130  77 206 220   4 200 120  16 194 195  24  64  32 196 120 118\r\n",
      "  68 248 107 206  10 208 180 189 120  23  40 185 126 160  24 164 216   6\r\n",
      " 246  32 243 136 203  94 252 202  88 203  88 148  68 224 142 251  44  55\r\n",
      " 198  68 182 192 148  88  32 234  16  12 136 204   6 207 238 205  52 144\r\n",
      " 212 164 208  68  94 110 208 181  68  57 116 128 136 217  36  39 128 248\r\n",
      " 144 248  54  75]\r\n",
      "Epoch ID=45800 \r\n",
      "\r\n",
      " D-Loss=0.5116152763366699 G-Loss=10.203522682189941\r\n",
      "[240  56 234 230  97  68  53  50  54  28  70 134 130 177  45  35 127 151\r\n",
      " 178  82 109  73   6 203  64 152 182 214  66 156  84 178 108  32  20 130\r\n",
      " 125 112 139 122  84 147 162  18  64  50   8  54 190  33 216  16 232  74\r\n",
      "  52 132  85  88  86 243 133  73 220 236 176 196  56  88 118  12 202 172\r\n",
      "  25 120  92  55  62 132 186  22  76 211   4   3   4  81 147  54 124 176\r\n",
      "  28  39  57 139 112 144 140 176  48 201  32  30  62  64  43  64 133 123\r\n",
      "  44  80 137 166  64 202 248  73 234 174 175  16  20 118  26 128 106 224\r\n",
      " 196  11 120 170 112 234 185 242  24 123 204 246 170  68 118 164 142 160\r\n",
      " 240  16  47 112  22  34 244  46 194   4  35 206 204 240 226  21 188  38\r\n",
      "  28 224  74  71 108 236  78   6  64  64  92  18 244 164 112 178 202  40\r\n",
      "  83  42   0 226 200  48 177 200 237 248 104 201 146 180 200  52 100  10\r\n",
      " 186 240 116  46 255  46 140 204  46 254 214 248 201 220  67 104  49 152\r\n",
      " 241 200 214 132  24  84  82 150  88  53 102  72 240  46  85  81 138  84\r\n",
      "  78 174 100  50 166  31 102 215 213  30  26 132 108  73   3  40  60 172\r\n",
      "  36 252 212  88]\r\n",
      "Epoch ID=45900 \r\n",
      "\r\n",
      " D-Loss=0.5174762010574341 G-Loss=9.477018356323242\r\n",
      "[ 88 171 220 254   6  46  30 138  57  54 121 182 145  50  65  24  68 154\r\n",
      " 126  36 193  95  84  31   0  56  22  70  27   3  38 252  18  40  70 170\r\n",
      "  28  84  78 140   0 231  88 156  80 110  60 134  36  10 250 206 230  18\r\n",
      "  11  16 193 170 187 158  68  90  48   4  68 174  88 183 133   4 132  50\r\n",
      "  60 208 208  15  96  50 245  16  22  92 245   2 103 242 202 159 140  96\r\n",
      "  90 120 169  21 107 197 248  56  34 142  56 155  56  32  16  64  52 218\r\n",
      " 101  92  66 212  21 255  42  47  80  98 112 210 246  10 232 160 251  19\r\n",
      " 136  92  96  96 186 208 144 186  59 103 152 242 200  82 175 100 210 192\r\n",
      " 176  42 103 217  89 101 248 184 123 218  72 224 226  44  51 200  88 128\r\n",
      "  48  78 116  93  88 187  31 116  74 120 156 206  61 158  28 200 153  83\r\n",
      " 106  12 216 174 238  48 124 105 188 234  98 108  25 124 148  11  60 167\r\n",
      "  21  14 197  34 242 138  84 169  64 204 247  54 158 148 146  10  86  72\r\n",
      " 109  68 196 186 228  76 112  79  12   2 244 117  28  95 103 188  52 204\r\n",
      "  84 100 142  88 174 128  48 197 238  85 232 124  44 133  59  80 168  64\r\n",
      "  56 210 178  58]\r\n",
      "Epoch ID=46000 \r\n",
      "\r\n",
      " D-Loss=0.5178768038749695 G-Loss=9.095781326293945\r\n",
      "[ 64  52 184  87 217 202 100  48 120 178  16 188  38 110  12 120 200  48\r\n",
      " 144 192 193 124 172  33 134  48 142 102  54 246  54 252 152  70 166  24\r\n",
      " 174  38  30  30 180  32  48 107 148 172 232 188   6  20 166  20 193 232\r\n",
      " 115 134 163 207 156 112 127 254 120 124  64  14  20  51  31 130 250 166\r\n",
      " 225  32 138 212 106  66 130 172  20 110  28 218 224 210 218 174  80  36\r\n",
      "  15 124 117 218  14 105  64  52  40  65  96  86 181 180 237  72 143  11\r\n",
      "  62 132  66  36 140 172  57 204   9 172   5 132  78 188  22  49  90 228\r\n",
      "  44 121 164  52 228  44  80   3 160  35 210  64 210 142  72 117 202 154\r\n",
      "  43  92 243  98 169   5 136   0 252  78   4   8 118  98 159 134 128 194\r\n",
      " 208 113 148 134 160  32  37 146  73 228  44 181 240 120  48 200 181 228\r\n",
      " 161  82  28  19 179 208  63  56  53 209 220  77  25  28 144  12   0  58\r\n",
      " 114 208  91 188 236 108 166  71 144 120 138 166 158  88 186  16 207  92\r\n",
      "   3  24   6  30 180  68 188 112  88 226  92 200 194 128 118  15 173  92\r\n",
      "  34 104  54 124 168 208 134  34 182 208 116  48 104 250  57 109  16 152\r\n",
      " 102 118  60  60]\r\n",
      "Epoch ID=46100 \r\n",
      "\r\n",
      " D-Loss=0.5189921259880066 G-Loss=9.77265739440918\r\n",
      "[112 220 144  64 200 146  27 218 244  58 109 148 234 152 136  48 238 196\r\n",
      "  44 174 124 254 223 151  31 246 186 252  76 238 168  32  10 134  93 142\r\n",
      " 172  92  91 228 130 219 218  23 100 109 220 160  44 186 252 190 174 164\r\n",
      " 114  28  60  40  32 175   7 144 254 236 160 140 112 174 168  80  27  60\r\n",
      " 138 186 232 144 122  86  36 148 209 103  79  62  76  54 208 126 130  72\r\n",
      "  53 243 170 149 147  85 144  52  92 124 224 144  62   2 198 187 142  52\r\n",
      " 206 138  22  98 133 178 168  72 120 224 182 164  44 211  44  90 123 162\r\n",
      "  58 104  52  16  50 135  59  64  24  94 128 127 146 136  93 208 246 154\r\n",
      " 100  92 232  58  74  75 181 246  89 174 248  22  23 162 108  31   0  68\r\n",
      "  13 156  24  15 248 196 115 228  37  80  91  81 166 108  40 232 146 154\r\n",
      " 219 240  92  15 105  28  25  14  92 242  52 251 220   6 115 106 230  26\r\n",
      " 122 224  37 164 145 181 184  75 230 200 114 192  77  44 161  28 250 140\r\n",
      " 174 219 238  86 208  72 150 122 248 237  66 118  30 245 230 240 208 146\r\n",
      "  16 120 172 214 100  32  10 202   0 150  28  91  69 151   0 245 254  68\r\n",
      " 148 135 224 192]\r\n",
      "Epoch ID=46200 \r\n",
      "\r\n",
      " D-Loss=0.5307526588439941 G-Loss=8.682918548583984\r\n",
      "[240 112 214 115  20 188 150 154 124  80  82 230 179  76  88 252  38 212\r\n",
      " 154 238 248  79 182 191  78 248 168 138 225  74  26 176 212 100 165 209\r\n",
      " 204 176  96 186 160 190  76  43 204 255  56  24 106   4 236 231  32  47\r\n",
      " 246 168   5 108  19  56  14 126 208 128  22  54   8  70 237 240 200  84\r\n",
      " 220  40  54 126  52 230 208  52 150 138 113 100 160 138 160  72  28  48\r\n",
      " 205 162  98   4 254   6 152  88 220 106 240 156 140 241  13  10  12 167\r\n",
      "  98  84 229  71 215   6  53 217  64 152 230  70  17  82 251 102  15 164\r\n",
      "  15 128  40 128  62 173 138 121 170  75  16 152  48 174  80  64 152  71\r\n",
      " 136  80 182 157  15 173  92  72  60 204  84  25 180  60 141 206 208 146\r\n",
      "  18 180  38 166 172  34  77 126 171 180 111  84  47 212 120 206 238 100\r\n",
      " 157 108 126 152 227 122 139  24   3  11  34 177  85 138  88 150  76 182\r\n",
      " 156  94 174  95  84  36 128 234  92 228 144 219 254  32 154  97   9 156\r\n",
      "  16 116  22  34  26 131 190  67 162  41  48  82 174 216 227  60 181 193\r\n",
      "   6  52  35 216  30  16 200 122 128 223 124  90  13  78 168  86 136 240\r\n",
      "  49   0 103 100]\r\n",
      "Epoch ID=46300 \r\n",
      "\r\n",
      " D-Loss=0.521020770072937 G-Loss=9.418143272399902\r\n",
      "[252  48 138 225 247 187  71 158 168 148 206  88 197 153 136  46  16 171\r\n",
      " 175 112  19 110 125 237  23 236  16 218 240 128  88 116 240  84 143  59\r\n",
      "  28 236 182 240  84 152  84 116 176 239 156  79  78 191 136  26 144  51\r\n",
      "  60 216 202 148 235  36 137  56  12 128 200 128 212 206 149  12 190 104\r\n",
      " 127  92 146  84 128  50 207 104  83 240 120  90 144 233  44   8 102  96\r\n",
      " 255 102 152 222 199 186  18 117 146  88 232  99   6  10 147 224 216   0\r\n",
      " 104  12 199 155 247  73 188 210 218 242 250  52 132   0  84  88 174 116\r\n",
      " 244 201  56 214 188  21  18 130 144 112 136  84 220 136  38 120 236  78\r\n",
      "  16  75 115 100  76 177  94 146 230  91  20 250 184 196 116 207 224  44\r\n",
      " 170 216 212 254  12   4 186 176  88 244 160  34   1   0 188 146 221  76\r\n",
      " 110  52  74  36  56 134 221 228 112 255 156 114 137  48 124 132 206 138\r\n",
      "  92  99 173 109  14  41 148 180 124 144 197  29 251 140 235 191  71 123\r\n",
      " 171 116  10 178 202 192 196 150 172 151  25  51 200  81  63  94  80  18\r\n",
      "  24  96  88   4  45 128  72 220  41 165 146 166 134 101  80 117 254 133\r\n",
      "  80 224  88 135]\r\n",
      "Epoch ID=46400 \r\n",
      "\r\n",
      " D-Loss=0.4960331320762634 G-Loss=7.950648307800293\r\n",
      "[194 246 220 227  10  97 131 171 238 106  52 146 246 217 101 115 228  32\r\n",
      "  58  74 148  53  51 225  75 182 162 240 227 210 251  36 160 128 133 221\r\n",
      "  76 208 165 207 113  74 154 160 164 217  96 140 184 160 168  17 159  82\r\n",
      "  60 212 237 204 210 209 130  87 252 192 160 104   8 118  16  24 249 118\r\n",
      "  21 120  45 233  96   8 216  16  85  50 187 250 218 197 144 116 228  10\r\n",
      " 175 100 246 100 119 106 168 174 114  42 140  44  62 171  26 169  36  83\r\n",
      " 103  42 128 137 147 187  57 160 201  96 173 106 254  64  97 171 188   0\r\n",
      " 240 169  12 240 124  12  32 154  20 126  19 180 160  98  56 159 240 122\r\n",
      " 142  96  26 195 240  91 184  95  66  26 124 216  48 104  62 124  63 240\r\n",
      " 123  42 242  87  84 145 115 178  55 136  67 116 224 252 216 152 255  22\r\n",
      " 244   0 130 195 115 172 117 106 197  78  26 226 150  98  12 108 182 154\r\n",
      " 145  36 166 164  58 221  14 157 232  64  50 213 160 168 160  19 205  16\r\n",
      "  50  48 246 105  32  76 208 252 204 197  97 138  72 107 119 102 118 120\r\n",
      " 136 100  50 212 152 104 104 162  58 142 144  72  89 188 131  22 112 228\r\n",
      " 100 212 214  32]\r\n",
      "Epoch ID=46500 \r\n",
      "\r\n",
      " D-Loss=0.5025639533996582 G-Loss=10.290360450744629\r\n",
      "[240  59 170  12  74 118  59 110 199 245 152 220 144 160  24 252 186  98\r\n",
      "  16 192 199 237 209  48 158 220 159 148 154  65  79  10  98 220 245 131\r\n",
      " 212 216  77   4   0 238 184  99  36 138 108 226  92 122 136  31  62 250\r\n",
      " 238 252 113 206  78 123   8 103  58  78 255 174 239 217 126 174 205  85\r\n",
      " 168  80 226 163 103 222  92 200 208 152 224  18 113  90 130  53 239 152\r\n",
      " 203   7  55 223 114 129  74  65  85 235  56  58  82 164 104  91  41 220\r\n",
      " 163 240  21  27  64 175 222 172 116  78 142  89 118  20 251  91 235  92\r\n",
      "  54 113  64  68 124 130 223 107  10  54 162  68 236 160 119  87 215  18\r\n",
      "   4 218  36  10 180  67  26 222  13 118  16 254   7 244 141  60 202 108\r\n",
      " 160 141 162  17 164 107  91 136 232 228 143 213  75  26  16 138  64 182\r\n",
      " 231  14 152  85 226 177 149 146   5  49 200 199 233 128 198 185 103  28\r\n",
      "  37  38  92  35  79 214   4 180 188  29 193  92  81 172 139 120 244  40\r\n",
      "  37 108 122  71   4  90  60 151   0  47  67 147 152  61  39  94 193  82\r\n",
      "  32  36 133 143 140  44 204  92 169  86 252 208  96  84 154  56  64 109\r\n",
      " 100  36 240 177]\r\n",
      "Epoch ID=46600 \r\n",
      "\r\n",
      " D-Loss=0.5575899481773376 G-Loss=7.9434380531311035\r\n",
      "[124 110  60  47 209  52  89 134 244 209 151 253 121 118 195 170  60 185\r\n",
      "  86  88  86  91  18  40 139 120  42 172  59  92   5 198   8  61  84 237\r\n",
      "   0 104 250 117 134 143 240 171  68 150 248 168 216 101   6 109 238 246\r\n",
      "  54 122 166   2 132 254 167 224 140  66 136  16  84  80 140  92 199 254\r\n",
      "  25 200 110 137 122  48  98 220 188  40 219 160 232 147  29 244  82 104\r\n",
      " 198 254 149 253 221 150 132 170  96  69 180 209 150 218  62 152 141  26\r\n",
      " 125  20 231 129  93 184  55  35 166 144  75  40 168  30 102 150 227 100\r\n",
      " 206 112 180 202  62  13  22 255 148 228 248 124  12 126  33  89 216 106\r\n",
      " 240  20  78 132  95 124 127 132 113 158 106   8  35 228  54 138  40  60\r\n",
      "  40  75  96 194 204  47 123 235 135 160  65  59 218 192 192  70  91  61\r\n",
      "  66 150  98 242  53  60  42 178  34  81  68 143   9  60  46  42 122 134\r\n",
      "  54 160  72 209 176 209 254 235   2  72 150 234  45 176  42  74 112  54\r\n",
      " 103  50 146 182 228 212  16 170 198 175 227 156  52  97  23  72 172 158\r\n",
      " 136 106  69 231  80 208 244   4 156 176  88 176 192 243 208  90 232 134\r\n",
      "  40 112  28  54]\r\n",
      "Epoch ID=46700 \r\n",
      "\r\n",
      " D-Loss=0.5233033299446106 G-Loss=9.146660804748535\r\n",
      "[124  96 148 174  18  46 110 240 118 155 129 135 142  64  73 122 128   5\r\n",
      " 180  20 174 228 243 136  60 166  52 192 149  74 246   8 132  30   2  65\r\n",
      " 151 252  32  51 218 169 244  74  44 143 224 248 102 166 192 180 198 180\r\n",
      " 155  24 204 175  30 239 205  38 200  48 106 222  66  48  21 228 160 145\r\n",
      "  96 120 104 109 218 202  65 176  86 128 189 242  24 190 163 107 182 224\r\n",
      "  96 238  18 234 179 104  40 210 151 243 116 128 179 116  88 226 124 222\r\n",
      " 131 104 206 245 194  61  30  79 100 168 252  68 229 158  43 170 188  40\r\n",
      " 212 234 228 138 190  28  45 174 140 184 192 155 208 172 163 239 249 250\r\n",
      "  18 128 166  54  65  90 216 148 187  88 214  28 135  26 240  74 252 180\r\n",
      " 198 238 236 105 200   4 152 101  38 192 163 235  30 184 180   7 110   0\r\n",
      "  76 250  76 153 162 114 104 184 144   0  48  40 146  52 130 244  96 255\r\n",
      " 206  63 236 149 192 112 136  98 170 222  30 153 220  88  95  79 195 232\r\n",
      " 109 140 248  96 116  75 176  81  96  66 238 138 204 215  38  54   1  42\r\n",
      "  16 200 195 255   8  17 184 143 159 207   8 112 166  17 126 222 163 139\r\n",
      " 172 188 184  35]\r\n",
      "Epoch ID=46800 \r\n",
      "\r\n",
      " D-Loss=0.4983816146850586 G-Loss=8.243932723999023\r\n",
      "[112   8  84 164  54  76 210  56  88 200  94 122 106  46   8  40 122  69\r\n",
      " 124 210  87 209 249 224 172  72 201 248  44   7 238 124 248 160 133 162\r\n",
      " 124  48 116 141 220 132  32 174 236 150 192 123 232 108 206 251 216 164\r\n",
      "  46 120 108  29  18  13  30  71 126 204 248  90  76  56 140  14  92  58\r\n",
      " 210  80  25  86 134 224 144  82 246 252 128  14 254 229  32  72 240 132\r\n",
      "  70   2  44  50 239 154  40  78 238 250  64  53 104 200  30 114 150 239\r\n",
      " 254 102 248   6 182 252 248  71 250 144 115  22 218 163 125 195 216 198\r\n",
      " 149  83  96 206  16 194 187 209 112 188 150 156 108  52  49  99   0 122\r\n",
      " 154 246 156 177 185 250 175  50 187   6 252 232 142 216  31  85 176 232\r\n",
      " 166  36 212 194 176 124 151 252 176  64 225 235 100  40 216 145  88 220\r\n",
      " 143 100 192 230  30 176 180 108  78 184  44  28 175 166 191 211 136 173\r\n",
      " 236 174  61  10 173  56 204   8 152  72 117  24 133  80 250 114 229  14\r\n",
      " 196  53  56  29 214 118   4  83 232 159  44 146  40 229  64 200 121  48\r\n",
      " 152   8  68  57  52  84 124  15  89 173  96 231 204   1 166 249   8 136\r\n",
      " 156  20 169  54]\r\n",
      "Epoch ID=46900 \r\n",
      "\r\n",
      " D-Loss=0.5010268688201904 G-Loss=8.974860191345215\r\n",
      "[ 44 114 220 227  27 112 152  74  34 145  85  14 172   9 190 198  36  46\r\n",
      " 204 172 158 167 218  68 174 250  67 110 232 202 153 151 218 176 173 201\r\n",
      " 118  26 144 165  86  91  32 238  28 229 168  82   4 139   2 222 184  29\r\n",
      " 129  70  22 237 244  66 213 144  35  44 230 196 142 194 127 140 181 220\r\n",
      "  53 204 117 169  62  33 125 170  80 197  15 224 112  71 179 176 136 248\r\n",
      " 134 168 176 216 142  64  16 200 247  79 208 230 134 181 161 196 243 227\r\n",
      "  34 112 214  12 253  28 236  32 120  92  34 252   9 144 141  12 188 110\r\n",
      " 248  44 136 252  18 159  48  54  56 167 197 170  52  60  11  75  59 128\r\n",
      " 120   0 179 134 112 200 203 211 228 228  11 126 160 120 140 210 236 252\r\n",
      " 213  10 148  56  48  46 154  50  39 116 155 134 186  16 184   1 115 227\r\n",
      " 142 138 165  45 128  72  74   8 123 244 128   8 151 208  38 196 158  43\r\n",
      "  18  18  80 196 236   8  42  75 165 103 100 104 154 252 251 119 173 198\r\n",
      "   6 164 118 144 108  84 138 168 140 212  26  40 224 104  16 112  78 136\r\n",
      "  24  72  51 140 210  81  20 179 210 172  96  92 117   2 144 210  88 182\r\n",
      " 158  26 102  80]\r\n",
      "Epoch ID=47000 \r\n",
      "\r\n",
      " D-Loss=0.5197060108184814 G-Loss=8.058693885803223\r\n",
      "[200  35  92 188 112  20 114 159  72 195  52 124  91  50  16  56 102 162\r\n",
      " 214 142 153 199 161  76 231 156  54 124 232 168 115 206  72  10  86 220\r\n",
      " 156 232  80  84 244 118 248 205  42 176 228  11  48 130  58 239 244 164\r\n",
      "  14 100 213  46 229 113  64 232  90  46 226 138  76  46 143 152 101  75\r\n",
      "  30 128 180   2  47 158   4  55 166 136 226 235  22 157 142 182 112   0\r\n",
      " 219  11  41 162   9  52  32 174  50 250  16 216  52 188  32  43 204  68\r\n",
      " 142 110  70  50 216   1 201  36  30 178  36   6  58 182  20 228  45 246\r\n",
      " 161 218 204  36 147 210  92 139  50  28 124 183 240  40 114 152  10  58\r\n",
      " 165  88 168 212  84 183 166 164 184 162 178  38  58  88  43  22  50  88\r\n",
      " 252  19 216 213 132 194  81 100 104   8  39 142 235 174 104 150 238 112\r\n",
      " 127 240  84 122 166 130  82 208 151 194  78 156 107 102 139 107 106 171\r\n",
      " 140   7 115 176 239 250 210 253 118  56  60 125 180 160 228 146 155  80\r\n",
      " 101  84  22 144 208 126 200 173  72  24 225  34  86 240 132 109 158 166\r\n",
      "  32 232  22 124  65  72 164 239  96 203 212  96  42 181   4  48 224 214\r\n",
      " 182  96 104  95]\r\n",
      "Epoch ID=47100 \r\n",
      "\r\n",
      " D-Loss=0.48849067091941833 G-Loss=8.254165649414062\r\n",
      "[ 36 194  56 166 184  38 222 191 248 236 149 205 121  48 168 123 142  79\r\n",
      "  30  98 223 206  96  16  33 100 178  90 188 218 106 102  74  56  62 248\r\n",
      "  14  34 214  54 152  80   6 150 252   8  60  78  92 203  44  29 116 176\r\n",
      "  43 142 249 124 123 129  10 168 176 252  40  78  96 163 143  52  62  56\r\n",
      " 251 160   9 132 248 102 191 100  64  58 249 246  45 196  24  38   0  32\r\n",
      "  61 143 120  10 227 116 168 248  46  80  68 132 154 255 200  54  64 142\r\n",
      " 157 144  47 116  55 100  41  16 147  10 183  24 140  51  57  50 142  24\r\n",
      " 177  38  16 250  63  19   1  22 128 174  20 245  10  40 208 111 152 124\r\n",
      " 173 147 233 172 106  72   2  80 212  28 146 114 176 160  25 194 151 250\r\n",
      "  92 115 170 168  42  86 168   1  37  24 169 112 106 192 100 118 161  36\r\n",
      " 162   0 240  77 174 156 240 116 177 113  80  83 133 251 185  80 159 173\r\n",
      " 108 216 193 241  64  98 176 225  32 130 173 236  28 204 138 235  66  52\r\n",
      " 127 180  26   3 216 150 146 220  43 122 102  29 220 230 214 234  55 188\r\n",
      " 128 184 210  52 214  44 236 121  50 229 122  26 140  47  64 123 142  57\r\n",
      " 214 170 162 180]\r\n",
      "Epoch ID=47200 \r\n",
      "\r\n",
      " D-Loss=0.5077768564224243 G-Loss=9.132365226745605\r\n",
      "[166 104   0 193 138 194  96 138 200 110  94  28 107  78 135  61  76 114\r\n",
      " 194 120  50  50   5  41 128 170 145 180 110 175 182 146 196 240  26 176\r\n",
      "  60 120  13 245 140 187   0 148 214 222 224  28  54  69 108 104 171 210\r\n",
      " 222   0 149 179  20  33  11  54 224 212  24 254 100 237 242 146 228 146\r\n",
      " 228 240  49 196  28 104 199 104  13 122 238 141 240  91  49  21 240 200\r\n",
      "  50 103 216  64 162 251 184 254  95  26 112 252 239 162 185 218 134 209\r\n",
      " 143  42 148  66 106 237  13  22  71  76 230  60 135 126 198  62 250 235\r\n",
      "  85 222 168  45  96 245  39 215  44 134  40 241 250  72  13 181   7  44\r\n",
      "  74 224  48  28 123 160  20 160  37 136 204 119  94 240 206 231 118 124\r\n",
      " 129  20 242   8 240  66 121 225  15 148  37 117 202 162 244 255 254  54\r\n",
      " 216  24 139 170 226  96 232 151  94 145  38  62  38  12 157  17  98 118\r\n",
      " 214  93  91  83  64 177 216   7  56 100  20 134 198 252 160 244  22  77\r\n",
      "  22  40 140 196 229 204 112 121 124 189  72 187 195 235 148 170  70 136\r\n",
      " 166 114 236 242 200  12  32 213  40 138 196 232   3 145 142 199 251  96\r\n",
      "  18 132 220 202]\r\n",
      "Epoch ID=47300 \r\n",
      "\r\n",
      " D-Loss=0.49518901109695435 G-Loss=7.564304351806641\r\n",
      "[242  52 214 227 184 238 192  26  44  88  32  40 254  41 136 136  96 132\r\n",
      "  31 244   5 174 140  89 224 180  41 140  96 254 127 208 240 232  71  21\r\n",
      "  78 208  93 218 233 254 192 181  16 183 132 250 206 178 200 231  48   6\r\n",
      " 158  48 133  92 248  82 205 149 160 136 180 248 180  64 178 190 130  41\r\n",
      " 173  96 148  12  84  47 146 196 214 148 254 224  44  58  66  16  92 152\r\n",
      " 170 223 178  38  19 151  84 184 222 254 136 107  92 150 182  70  11  93\r\n",
      " 184 200 155 134 188  29 113 155 213 152  23 184 108  67 239  13  24 148\r\n",
      "  75  97  24  60 153 200  24 211 218  16 158 212 246  40 207  90 146  32\r\n",
      " 220 150  26 227 113 178 143 159 166 224  24 128  61 216 206 201  28 228\r\n",
      " 172 216 226  43  48  82 206 194 243  60 120  58  48  16 204 182  65  40\r\n",
      " 168 144  89 243  89  52 149   8  15  25 174 224 251  59  51 124 176 242\r\n",
      "   0  96 238  77 198 214   4  72 234 106 157  29  68  12  95 123 197  68\r\n",
      "  90 252  22 128  80 224 222 147 152  94 142 242  88  70  35  96 244  62\r\n",
      "  82 228  93 251 208 188  48  24 254 180  68  64 211 161 150 103 253   2\r\n",
      "  44  18 204 244]\r\n",
      "Epoch ID=47400 \r\n",
      "\r\n",
      " D-Loss=0.5237752199172974 G-Loss=9.292314529418945\r\n",
      "[ 24 184 202 133 232 216 218   3 148 108 205  79 170  66 123 152 137  78\r\n",
      " 200  18 208  39 152  49   3  96 130 168 128  64 255  86 200   0 142 147\r\n",
      "  28  88 140  34 132 214   0 224 160 254 228 148  79 115 228 153 193 200\r\n",
      " 162 206  92  24 182  31 245 197  43 136 136  72 108  44  80 194 186 245\r\n",
      " 134 168  42 126 116   6  57   4 241  52  40  12  68 168 200 174 252 204\r\n",
      " 184 108 146  76 188  54 176  70 220 152  56 194   2   8  86  20 125  62\r\n",
      "   8 202 120 214  76  62 111  57 236 112 143 172 134 134 109 136  31 170\r\n",
      " 106 182 232 234  54 219  70 100  88  20 234 193 176 144 157  44   8 120\r\n",
      " 156 152 137  80  18 214 179 124 171  93   7 222  54 112  71  28  26 212\r\n",
      " 136   0 102 172 172 146 121 116 166 224  32 220 194 232 136 130 131  76\r\n",
      "  96 220 180  58 156  52 131 228 134 195 160  45 162 236 196  90 112  17\r\n",
      " 218 128  65 135 135 145 152   1 224 192 177 155 119  68 183 227 223  84\r\n",
      "  83   0 142  83 244 143 220 231  64 145 248 246 216 104 202 216  74  72\r\n",
      "  42 220  56   0 192  46 172 194  65   8  64  16 158  35 212 207  48 116\r\n",
      " 120 134   6   4]\r\n",
      "Epoch ID=47500 \r\n",
      "\r\n",
      " D-Loss=0.5158602595329285 G-Loss=7.850000381469727\r\n",
      "[144 246  98  22 159  62  10  32 160 125   9 177  32 121 229 176 176 220\r\n",
      "   4  76 116 112  22 245  36  63  81 112  30  39 135  56 160  90  53  83\r\n",
      " 136 196  15 140 237 102 204 245 152 199 232  22  91 209  78 181 239 166\r\n",
      " 194  10 201 228 234 210 126 198  42 236 184 184 216 182  91 112 151  84\r\n",
      " 131 232 174 134  86 171 118 120 254  44 127   2 214  74  60 150  62 128\r\n",
      " 217 159 191  43  45 231  32 248  47  64  40 214   5  57 177 186  70 209\r\n",
      " 137  92 120 171 229 137  48  32  66  14  90 191 234 208  70 206 176  12\r\n",
      "   2 123 108  35 139  72  28 191  28 200  38 135 168 164  68  48  80 194\r\n",
      " 236  90 236 173 167  22  89 142  17 132 246 116 236  50 203  87  73  60\r\n",
      "  37 222 198  59  54 135 211  81 201  44 246 126  31 180  80 139 116 232\r\n",
      "  50  26  92  71 184  56 237 171  98 102 210  75  14  94  84  13 202 103\r\n",
      "  90 130 164 205 242  19  94  92 122 132  98 201  91 144   4 112 124 126\r\n",
      " 228 192  26  52 194 202  90  78  26  57  24  61   4   9 106 203 202 172\r\n",
      " 130  80 127   3  69 228  26  58 120 250 186 164  27 211  48 245 156  22\r\n",
      "  60  16  32 186]\r\n",
      "Epoch ID=47600 \r\n",
      "\r\n",
      " D-Loss=0.5182565450668335 G-Loss=9.494062423706055\r\n",
      "[116 104 132 240 158  44 199  96 222  77 106  74 110 141  22  65 144 220\r\n",
      " 244 200 212  30  66  70 136  34 193 208 136 232 190 232 164 180  44 192\r\n",
      " 226  56  49  91 206 230 184  14 162  22  80 178  50 244 140 163 240 224\r\n",
      "  57  77  42 239 161 180 112 253  98 174 148  80 248  65  34 248 219 186\r\n",
      " 255 144  30  25 230 248  24  24 227 236 130  56 204 130  68 159  88   2\r\n",
      " 234 174  30 152  34 234 228 167 120  65 216   3 177 210 118  17 104 235\r\n",
      " 138  64  34 112  61 236  99  95 136 192 173 205  40 147 120  48  43 248\r\n",
      "  67 189 236 137 110  11 158 105 156 192  72 226 208 252 140 169 106 229\r\n",
      " 239 128 119 200  36 170 172 244 245 200 140 216  32 172  73 227 121  56\r\n",
      " 164 107  84  89 138 100  20  14 175 116 132 173 224 180  96 186  79   8\r\n",
      " 109 120  12 117 106  64 102  38 200  42 240 199 224  82   8  88 100  58\r\n",
      " 179  22 228  31  56  81 218 126 152 168 252 199 186 136 154 175 150 212\r\n",
      " 120 142 190 231 140 180  72  99 244  57 114  51 208 223  89  12 138 180\r\n",
      "  64 102 196 180  74  98  94  10 161  18  44 156 218  95  63  64 136 148\r\n",
      "  64 252  21   3]\r\n",
      "Epoch ID=47700 \r\n",
      "\r\n",
      " D-Loss=0.5231391787528992 G-Loss=7.395994663238525\r\n",
      "[156  36  88 232  59  52  35 144 184 163 115 164   4 254 150 110 230  73\r\n",
      " 196 102  28  13  94  25 238 173  68  73 166 186 176 120 134  92  51  19\r\n",
      "  30  80 141 198  90 224 160 177  52  99 168  34 219  18  36   4 176  78\r\n",
      " 154 174  38  94  96 149 224 219 198  20  98 168 168  60 208  34 218  92\r\n",
      " 191 120 188  67 108  10 206  20  62 192 186 103  38 230  46 130  40  76\r\n",
      " 137  46 141 145  13  89   0 205   3  51 248 108  23  66 244  72 137  21\r\n",
      " 250 140 136 182 170 230 122 181 202 246 177  24  10  77  40 216 166 110\r\n",
      "   3 116   0   4  65 153  22  96 169 211 216   6 178  68 210 145 243 187\r\n",
      " 148 112  32  16 153 146   3  18 217 110 250 238  36 128 144 139 126 218\r\n",
      "  21 211 216 252  84 221 197  60 176 108   8 156 156  56 156  61  30 236\r\n",
      "  32  90   6  89 110 109 104 138  33 102 128  12 160 255 144 105 158 148\r\n",
      " 105 248 122   4 135 232  66 251 116  25 220 249 190 104  90 142  22 226\r\n",
      " 185 131 184  97 142  89 232  71 174 110 104 229 218 108 215  20 167 246\r\n",
      " 160 188  24  11   0 216 226 152 144 154 150  64 208 106 238  62  82 101\r\n",
      " 126   5 228 232]\r\n",
      "Epoch ID=47800 \r\n",
      "\r\n",
      " D-Loss=0.514693021774292 G-Loss=9.314204216003418\r\n",
      "[248  54 242 196 200  90   2  16 138 177  28 230 228 188  43 241 108 104\r\n",
      " 250 140  44 250  48  37  12  13   4 132 190 122  50  12 112 226 222 219\r\n",
      " 122  52 226 104  69 118 216  65 124 168 180 220 250  79 180 150  76 137\r\n",
      " 198 128 216  14 229  15 113 159 247 156  44  34 232 193  46 158  18 250\r\n",
      " 170  16   3 234  76 247 156  24  88 172  49 244 104 207 252   7 140 104\r\n",
      " 116 222 152 183 154  48 136 138 142 207 168 201  63 247  26 190  48 114\r\n",
      " 255 172 122 162 199  65  13 224  26 200 164  15 172  87  24 142 112 178\r\n",
      " 255  50 246  78  15  18  85 238 127  12  53 146  28 200  64 190 104 132\r\n",
      "  76  84 141   5   8  74  86 145  73 132 168 168 168 144 133 206 129 126\r\n",
      "  86 160 168 184  22 119  20 184 234 176  75 162 170 130 100  99 186 208\r\n",
      " 240 252 210 124  48 122 193 196 142 205  88  84 223  60  98 102 180  40\r\n",
      " 185 220 180  56 171  31  56  81 252 192 189  56 140  96 217  87 153 215\r\n",
      "  98 115  90 184 128 246 252 248 228  26 215 249  34 237  63   7 194 200\r\n",
      " 228 148  14 122 140 152 142   0 160 140 212 134   0  17  16  81 230 106\r\n",
      " 136 186 102 108]\r\n",
      "Epoch ID=47900 \r\n",
      "\r\n",
      " D-Loss=0.48934972286224365 G-Loss=8.3772554397583\r\n",
      "[252 188 255 218  56  42 248  42 105   4   6  90 130 179  46 255 151 104\r\n",
      " 248  72 200  85  37 222 168 252  37 172 170 168  74 137  34 216 109 202\r\n",
      " 127 156 141  24 131  53 152 108 230 198 152  28 200   8 248 180 211 105\r\n",
      " 194 194  55  54  66  63  53  92 250  18 160   6  84 237 135 188 101 136\r\n",
      " 162 240 170 204  68 229  50  18 212  96  21 236  30 200 186 218 194  72\r\n",
      " 155 160  36  70 224  44 252  56  38  42 186 165 113  56 212 155  68 171\r\n",
      "  54 224  97  49 147 209  64 106 222  20   3 157 246 159 210 110  98 210\r\n",
      "  38   7 116 231 148 141 186 118 140 226  44 112  88 240 252 198 172  76\r\n",
      " 129 154  23 161  47 206 153  28 240 119  52  55 156  14  38   6 190 180\r\n",
      " 231  44 208  17 156  79  69  35 122 220  72  25  42  96  48 136  95 238\r\n",
      " 177 230 136  35  17  72  22  49 146  41 236  61 191  36 115  14 155 188\r\n",
      " 244   4  16  28  36 193  46  61 224 208 140 212 245  64 166  71 119 116\r\n",
      " 128 174 124 160 146 191 224 228 226 171   2  31 204 160 160  47 206 194\r\n",
      " 194 102 224  71 204 108 248 240 131  90 226 196 244 146  67 152  86   6\r\n",
      " 118 170  59 138]\r\n",
      "Epoch ID=48000 \r\n",
      "\r\n",
      " D-Loss=0.5233989953994751 G-Loss=8.548712730407715\r\n",
      "[ 72 244  72 200 250  27 167  81   8 168  98  18 108 147 132 199 116  38\r\n",
      " 142 160  48  78 137 242 168 172 203  16 180 185 252 125 233  96 253 225\r\n",
      "  80  12 187 176 234  10 216  63  16  77 232 132   0  17  82  22 119 176\r\n",
      "  30 150 225 119  88 234  78 157 228  84 150 172  68 206 145 141 255 184\r\n",
      " 180 172 222 209 242 135  81 216 234 195  58 107 184  15 236   1 102 144\r\n",
      " 147 126 121  44  31 251 100 195 101 245 176 126  28 248   6  24 180  62\r\n",
      "  20 240  88  81 126 171 169 170 216 216  78 214 224  84  19  49 170  16\r\n",
      " 168  35  80 109 112 148 111 192  52 253  78 232  16 144 167 246  62  55\r\n",
      "  84  96 126 153 131 166  68 124 178  50 234  20   8 130 192  37 228 124\r\n",
      "  88  71  86  20  22  52 110 232 194 204 159 196  64 248 248 250 215  88\r\n",
      "  87 156 188 150  90 168  96 129  77 135 128 175 188 248 129  61  57  14\r\n",
      " 137 178  57 215  27 150  74  50 108 230 180 233 233 220 188 247 124 168\r\n",
      " 193  68 150 102   0 241 132 238 232 153 193   2 162 165  96  32 102  34\r\n",
      " 192 136 196 156 109  28  88  76 240  52 236 218 177  19 120 237 112  22\r\n",
      "  76 160 196  56]\r\n",
      "Epoch ID=48100 \r\n",
      "\r\n",
      " D-Loss=0.47074824571609497 G-Loss=7.870378494262695\r\n",
      "[206  42   0   8 119  14 168 252 124 208 180 244 129 206   9 148 166  86\r\n",
      " 105  41  98 137  31 139 220  60 112  78  65 248 181  26 240  54 235  73\r\n",
      "  32  88  50 136 214  28  38  42  76 139  16 144 228 169 148 176  70 100\r\n",
      " 173 192  42 140 226  98 209 224  42 248 170 142 216 212 197 122   8  36\r\n",
      " 242  32  45  31   4 180  48 138 148 182 206 232 176  64 126  12 214  80\r\n",
      " 170 103 174 102 170 204  28  36  78 125  16 193  72  49 204  88  61 185\r\n",
      "  35 164  74  33 248  40 134  69 123  12 114  60  43  71 228 132 251  28\r\n",
      " 188 221 204  49 240 238 180 202  20 115 112  12 186 236 178  25 185  28\r\n",
      "  62 113 153 224 208 129 137  95  42 121 213  84  26 146  68 254 244  32\r\n",
      " 144 148  38 199 140 105 168  48 182 248 148  52  60  16  48  28 153 252\r\n",
      " 119 176 148 251 151 100 252 242 139 106 160 133  12 166 156 100  84   1\r\n",
      " 248 236  35 203  82 198   8  79 234 174 112 104 215 208 102 194  72 208\r\n",
      "  13 192 200 222   4 156 252 244  96 234 188 207   0  92 207 196 226 234\r\n",
      "  80  80 164 145 115 156 252 245  26 111 214 108  46 228  76 138 216 211\r\n",
      " 220 194 184 139]\r\n",
      "Epoch ID=48200 \r\n",
      "\r\n",
      " D-Loss=0.5188284516334534 G-Loss=8.711336135864258\r\n",
      "[ 88 220 240 231  38  34  68  12 104 211 109  74  88  49 222  93 204 215\r\n",
      " 123 170 187 125 168 111  54  19 137 190 247 146   8 198   8 192 215 253\r\n",
      "  75 240  52 216 142 131 200 125 110  44 158 208 243 186 190   9  51  44\r\n",
      " 145 129 232  80 228  15  17 115  10 128 206 210 192  78 167 191 174 100\r\n",
      " 154 184 109   5  34  77 137 128 181 111 253 144 112  25 192 151 254 110\r\n",
      "  96  69  59  24 212 237 254 124 112 194 118 227 194 242 180 176 237 174\r\n",
      " 212 204 225 198 206 233 172  25  52  72 195 107 182 164  42  67  82  13\r\n",
      "  95  49 112  48  56 166   8  17 200 252  59  42 192 248  88 181 189 228\r\n",
      " 142 174 220 212 244 164  21  76 151  97 178  10  26 110  12 204  14 206\r\n",
      "   5 102 202 117 254 100 107  28  32  44   5 202 125   0  84 242 249 238\r\n",
      " 139 174 200  89 216 218  15 146  13  97 192 152 160  15  97 234 193 231\r\n",
      " 249  24 218  38 158 222 192 143  84  57  10 247 165  98  58  17  85 160\r\n",
      "  41 212 254 119 176 129 136  86   4 134 161 237 118 244 136 236 122 132\r\n",
      " 160 174 112  66  52  51  20 130 212 243  83   4 106  94 148 142 245 224\r\n",
      " 150 190  24 106]\r\n",
      "Epoch ID=48300 \r\n",
      "\r\n",
      " D-Loss=0.4606541693210602 G-Loss=8.374887466430664\r\n",
      "[164 158  98  76 252 152 246  96  40 136 131 155  52 161 233  25 238 191\r\n",
      " 156 152 238 178 254 244   0  72  68 232 186 168 224  40 228 226 108 158\r\n",
      " 178 176 108  95 138 119 236 222 140 164 252 116 168  76 252   6 114 130\r\n",
      " 179  48 204 110 241 212  65  91  64 168  92 194  80 162   3  66 118 121\r\n",
      "  67  88 234  63  20  46 191  34  59  48 157 192 100 217  61 136 112 104\r\n",
      "  42  45 215  18 244 172 204 234  58   5 124 225 176  70 137  50  17 177\r\n",
      " 111 208  20  94 164  65 223 237 166  36 204 168 164 253 204 201   8  39\r\n",
      " 143 248 140  38 178  58 206 238 132 228 160  12 172  12 174  12  32  18\r\n",
      " 176  41  58 212  24  12  41   4  65 166 224 134 156 210 138 158  16 206\r\n",
      " 140 180 226 233 140   8  39  28 116 156  48  16  92  32 188 130 100 138\r\n",
      " 216 216 134 125 154  10 152 124 225 134  68 229 194  82  42  81  28 174\r\n",
      " 218  36  91  99 190 135 108   7  84  41 235 104 172 220   6 169  52  42\r\n",
      " 139 130 116   4 182  80 190 188 136  36  37 169 244  68 202 134  58  92\r\n",
      "  24  88  65  78 168  18 108 111  68  53 198 108  92 160 153  48 162 248\r\n",
      " 124  77 188 228]\r\n",
      "Epoch ID=48400 \r\n",
      "\r\n",
      " D-Loss=0.521066427230835 G-Loss=8.341264724731445\r\n",
      "[232 158 108 140 168 207  58  68  72 209  53  33  83  21 110 206  84 165\r\n",
      " 178  42  69  85  86 184 196  64 133 246 170 202 124 150 132  20  46  80\r\n",
      " 229 240  63 186 208  45 192  76  84 252 180  52   6 116 200 228  79  52\r\n",
      " 185 174  84 185 199 157   9 241 248  16  42 186 116 205 230  80 112 228\r\n",
      " 155 248 161 189  80  28  79 135 128 110  97  78  26 108 176 139 237 104\r\n",
      " 189 207 139 151 247 212 224  50 242  63 196 185 248  84 218 122 169  49\r\n",
      " 192 228 125 120  75 213 147 196  54 196   2 153 176  12 118 103  76 102\r\n",
      "  28  61  40 208 133 175  92  27  90 184 180 102 114  60  98  70  12 102\r\n",
      " 212   4  66 229  17  50 112  42 212  10 224 162 210 144 125 209 133  92\r\n",
      " 213 128 124 187 224 139 138  64 114 232 218  25 208 232  16 250 143  44\r\n",
      " 133 168  12 208 148 129 250  98 119 187  64 146 203 129  78 132 100 190\r\n",
      " 240  27 129 193 174 216 119 195 240 230 251  69 243   0 116  38 120 184\r\n",
      " 157 174 142 212  80 168  42 163 108 145 101  86 194 146 234  53 205  93\r\n",
      " 136 120 226 245  52  94 174 160 108  27  92 228  49 114 108  68  88  52\r\n",
      "  40  24 249 138]\r\n",
      "Epoch ID=48500 \r\n",
      "\r\n",
      " D-Loss=0.48415178060531616 G-Loss=8.984201431274414\r\n",
      "[250  28   8  97 149 134 254 162 222   6 106 237   6  10  70 177  16  75\r\n",
      " 184 168  42  73  28 236  18  30 148 224  80 192 136  48 198  80  68  82\r\n",
      " 177 172  16  53 240  31 248  21 172 110  80  98 114 185  96  44 207  18\r\n",
      "  72 156 196 120  67 119  27  17  64 124 144  28  42 228 202 140  68 243\r\n",
      "  52   4   0  25 248  84 249  61 140  86 207 169 216 157 235 213 111 184\r\n",
      " 236   4 227 187  96  45  52 203  28 184 236 139 174  63   6 192   0 189\r\n",
      " 216 106  12 129  43 147 145  26  40 248   3  51 199 220 114  51 132 246\r\n",
      " 212 176  48   4 209 147  91 126 120 194  74 194  38 110 196 172 132  16\r\n",
      " 186 160  26  48  67  62 125  96 141 130 244 232  84 160 194  92  57  36\r\n",
      " 173  44 102  88 192  57 180   2 123  96 111   1  44 152  64 220  34  25\r\n",
      " 126  13  20  54 114 162 221 202 222 145 132 161 174 108   8 140  38 128\r\n",
      " 148  12 140  14 194 217 132 127   2 104 252 160   4  24   9 174 168  26\r\n",
      "  78  31 174  67   6 126 206 236 204 100  96 212 154 202 121 100 130 174\r\n",
      "  82 162 242 177  94 248 218  71 142 160 232 196   2 215 254 233  36  36\r\n",
      " 167   8 184  36]\r\n",
      "Epoch ID=48600 \r\n",
      "\r\n",
      " D-Loss=0.49639588594436646 G-Loss=8.242829322814941\r\n",
      "[100 166  44 169  42 194  78 182 248   3 251 100 166 156 145 114 234 175\r\n",
      " 164  84 194 114  15 192  68 232  87 176 125 142 244 254 242  28 240 124\r\n",
      " 105 102 135 117 254 120  48 163  50  66 172 206  20 214 188 213 219 136\r\n",
      "   0 156  43 192 202 211 165 183  91 184 192  30  80 135  80 180  61  24\r\n",
      "  89   4 217  37 190  70 169 170 161  54 236  47 181  51 117  10 116 148\r\n",
      " 245  26  70 199  77  18 200   4 162  75 192  83   0  34  40 137 214  34\r\n",
      " 160  20  91  28 162 218 214  47 186   8 156 230 198  41 120 128  99 248\r\n",
      "  72  87 132 152   4  98  57 140 122   0  51 108  68 176 107  84 108 232\r\n",
      " 200  92  10 146  70 176  33 250  61 223  32  32   4  61 250 188  86 240\r\n",
      " 189 152  14  11 120   8  96  86 228 180  90  41  62  88 148  76  72   4\r\n",
      " 170 104 112 165   4 248 195  20 120  39  94  56  96 220 128  18 116 210\r\n",
      " 234 152 162  12 169  99 188 163 210  96 144 157 132  56 144  87  78  50\r\n",
      " 242   6   6 232   0 138 160  98  56  56 170   7  66 134 134 219  62 101\r\n",
      "   4 114 120   3 114 190 180 195 230 167  22 202  12 215  18 195 118 230\r\n",
      " 154 216 230 112]\r\n",
      "Epoch ID=48700 \r\n",
      "\r\n",
      " D-Loss=0.5591370463371277 G-Loss=8.27927303314209\r\n",
      "[ 90  96  56 177 148 204 218  17 142  82  40  48 170 220 210 234 192 180\r\n",
      "  47  72 144  65 180 150 254 132  52 200  56 178  34   2 230 248 228 250\r\n",
      "  43 108 111  43 124  78 240  46 244 164 108  88  45   1  66 210  61  48\r\n",
      " 134  14 234 212 143  77 106 120  65 108  60 235  90  71 150 202 249 115\r\n",
      " 170 200 172  44  96  66  79  94  90  98 105 207 160 106 103 119 242  62\r\n",
      " 131 150  32 235 167 186  52 188 109 211 116 229  80  89  41  88 152 164\r\n",
      "  64 208   8  64 190  84  98 114  70 180 233  19  82  80  53 248 138 185\r\n",
      " 198 212  72  80  13 114  21 136  90 156  72 242 104 214 182  48 193  10\r\n",
      "  96  84 172 182 138  87 160  73 166 245 153 222 158 106 248 104 201   4\r\n",
      " 148  79 170 138  26 184 252 139  12 132 116  38 120  72 176  28   8 162\r\n",
      " 114 228  56   1 236  12 227 246 239 159 152 245 118  80  48  30  48 197\r\n",
      "  42  66  69 233  11  54 160 253  28   8 100  17 105 134  53  59  92  91\r\n",
      "  78  50  25  58  72  72 236 104  78  34 180 107 176  80 227 103  26 182\r\n",
      " 212 236  30   4 250 144 158  78  37  32  14 252 116 225  24 155 208  76\r\n",
      " 168 188 173 227]\r\n",
      "Epoch ID=48800 \r\n",
      "\r\n",
      " D-Loss=0.514229953289032 G-Loss=7.9093918800354\r\n",
      "[ 56 140 244  90 172 212 176 249 208   2 104 186  88 228  62 237  28 210\r\n",
      " 222  50 247  36 186 176 147 240  41  92  98 109 126 164 152 235  84 216\r\n",
      " 119 192 216 140 172 150 140  50 224 219 148 106 189  43 204 190  41 198\r\n",
      " 250  26 130 198  17 158 246 161 208  44 154 176 184 128 224 116  83 134\r\n",
      " 167  72 234 208 244  36  88 132 130 186  28 233  98  45  42  18 188 196\r\n",
      " 236 108  26   3 184  76 216  35 180  12  16  66 104 229 246 167 248  68\r\n",
      " 109 120  17  90 187  64 214  78  57 126 247  30 130 248  23  54  62 134\r\n",
      "  84  34 164 224  45 246 216 135   4  76 110 153   0 136 239 220 124 195\r\n",
      " 138  92 187  32  37 118 175 219  62 160  46 194 175 124 192 238 120  30\r\n",
      "  20  84  44  76  64 241  10 235  14 192  43 118  23 238 148 104 207 208\r\n",
      " 105 164  92 131 123  64  97  86   4  21  16  14 125  40  60 158 240  93\r\n",
      " 178 202  39 225  21 123 164   9 232  72  92 104  75  56 181 128  60 122\r\n",
      "  74 204 146   6  54 210 196 102  88 152 158   8  40  23 158  57 158   4\r\n",
      " 128  47 125 206 116 220 184  58   2 174 120 208 144  92  18 189  48  95\r\n",
      "  70  10 228 240]\r\n",
      "Epoch ID=48900 \r\n",
      "\r\n",
      " D-Loss=0.5002038478851318 G-Loss=9.026420593261719\r\n",
      "[240 162  40 253  70  56 255  40   0 118 234 156  66 238 150 166 138  50\r\n",
      "  26 236 226  61 163  38 176  48  26  38 102   6  76 142  72  72 188 136\r\n",
      "  30 208 103  71  20  96 160 242  80  18  92  36 230 204 254 228  56 154\r\n",
      "  15  76 200  76   0  82 141  32 113 124 202  92  10 158 108 240  74 192\r\n",
      "  55 108 108   8 104 242  50 220 246 126  42  92  11 207 212 173  98 200\r\n",
      " 142  50 198 207  33   0 144 128   6  94  16  82  90  76 109 238  56 209\r\n",
      " 210  68 101  50 105 245  63 178 107 190  71 250  98  74 103 243  28  50\r\n",
      " 171   6  32 104 162  68   0  36  64 160  88 192 182  30 218  47 113 110\r\n",
      "  20  40  46  74  80 172 224 124 126 160  56  74 168 216  71  76 140 196\r\n",
      " 182  84 232 141  36  56 204 104 208  48  58  58 249   4 112  24 219  12\r\n",
      " 122 240 160 107   0  76 223  46  94  96 152   5   3 156 247 182 128 165\r\n",
      " 255 102 224  14 255 118   8  52  80 212  58 130 199 240  86 129 237 182\r\n",
      " 188 136 226  81 188 127 214  39 128 146 150 188  36  29 225 252 244  72\r\n",
      " 252 190 184 110  32  72   2 164  22 135  34 176 224   4 129 218 200  44\r\n",
      " 228 228  64  46]\r\n",
      "Epoch ID=49000 \r\n",
      "\r\n",
      " D-Loss=0.4947816729545593 G-Loss=7.762333869934082\r\n",
      "[232 170 156  73  90  24 223 132 186  49  81  16 153 240   4  27   4   3\r\n",
      " 184  12  24 161 101  31 234 204 200  32 247 193  50 244 226 160 186 189\r\n",
      " 212 114 137 156  36  98 164 132 122 197 228 255 160   3 128 191 222  82\r\n",
      "  36  72 238 160  38 136 200 144  68  88 168  12 204 215 172 242 100 244\r\n",
      " 200 160  17 216  56  30  84 110 147 230 110 203  92 168 212  95 184 206\r\n",
      " 236 218  22  79 122 114 136 184  77 106 120 222 149   6 143  80 124 199\r\n",
      " 160 208 236 206 185 214   3 124   1  88 207   6 164 151 160  68  56 108\r\n",
      " 109 110  36 214 108 220  27 241 142  74  32 112 208  52  95 183 186  40\r\n",
      " 132 174 217 253  79 164   0 250 181 232  24 193 100 198  32 180 111 228\r\n",
      " 242  40  76 150 156  84  72 164 180 132 125  16 232  32  28  27 196  66\r\n",
      "  23  64  88 173 208 148 164  72 204 142 116  94 178 216  85 216 236 149\r\n",
      " 218  62  55  71 151 155  12 144  40  90 113  18 132  36 226  63  78 164\r\n",
      " 205 242 135  72 120 112 120  26 120 105 102 183 212  79 210  86 118  40\r\n",
      "  52 192  42  26  58 188  76 247 160 174 136  56 216 113 240   9 178  68\r\n",
      "  92  18  42  84]\r\n",
      "Epoch ID=49100 \r\n",
      "\r\n",
      " D-Loss=0.5049039721488953 G-Loss=9.16993236541748\r\n",
      "[210 156 234  24   0   8 129 116 178 106  24 225 172 222 116 232  34  38\r\n",
      " 218 168 238  66 217 215 182   1  14 210 176 177 141 128  30 211 237 203\r\n",
      " 100  28  86 251  60 150 182  68  36 123 128 146  36 228  28 173 252 234\r\n",
      " 106 232 180 237 136 122 146 122 232  56 128  52   8 243  27 156 216 176\r\n",
      " 119 166 150 232  32 182  29 240   8  61  80 116 136 179  38  20 116 100\r\n",
      " 112 226 114  16  36  84 132  40 117  41 136 177  20 255 210 165  76 133\r\n",
      " 214 206 252 203 177 105 114 186 234 104  99 234 188   3 135  66 145  40\r\n",
      "  13 246 214 240  89  12 217 147  14  60  86 217 104  38  10 125 134 254\r\n",
      "  24 120 127  68 123  28  16 252   2  28   8  60  48  18 233  78  65 234\r\n",
      " 125 106 175 203  10 222 130   0 157  84 204  15 150  52 216 110 251  50\r\n",
      " 212 230 140  53  94 208 174 156 174 251 128 173  20 228 202 107 147 231\r\n",
      " 167  32  55  66  62 157 224  33 176 246 251 244  75 240 130 174 170  14\r\n",
      "  84 223 102 223 170 183  72 114  76 125  96 245 226   7  52 216  58  44\r\n",
      "  80 244 250 250 244 138  86 218  33  62   8 209   3 225 212  58  42 230\r\n",
      " 148  85 244 157]\r\n",
      "Epoch ID=49200 \r\n",
      "\r\n",
      " D-Loss=0.5399341583251953 G-Loss=7.775734901428223\r\n",
      "[118 142 210  66   2 186 209 235  52  65 155   0  24 138  42  92 186 254\r\n",
      " 214 142  30  48  70  13 168  24  25 194 214 108  76 184 114 252 133 217\r\n",
      "   0  24  32 170  68 105 128 145 110   7  40  77 108  33 180 173 215 206\r\n",
      " 103  96 195 226  37  85  46  32 154 248  34   6  74 100  39 133 128 252\r\n",
      "  88  80 234 162 108  38  76 204 133 180 168 187  37 219 250 172 236 180\r\n",
      "  32 249 139 195  59  68  68  63 217  31   4 146  25 248 244  84 201 223\r\n",
      " 128 184 236 132  71   5 118 142 132  68 180 147  60 116  80 250 182 180\r\n",
      " 185 243 252 205 211  63 234  98  56 254 226 132 240  50  60  47 241  20\r\n",
      " 146 216 185 184 253 123 124  52 189  84 190  92  31  46 201 216  94  14\r\n",
      " 168  96 180 118 120 200 112  36 169 204 110  50 142 232 240  60 119  70\r\n",
      " 206  36 204 115  22  64 183  94  48 248  38 232 172 204 162 215  20 252\r\n",
      "  94 129 229 106  82 219  64 244 102  28 114 204 114  64  68 105 192 104\r\n",
      " 123  29 118 225  48 142 176 231  56   6  28 210 216  74  66 235 159 240\r\n",
      " 136  40  19 143 229 244 112 148 248   1 108  80 214 235 132  28 126  76\r\n",
      " 102 188  24 139]\r\n",
      "Epoch ID=49300 \r\n",
      "\r\n",
      " D-Loss=0.5007798671722412 G-Loss=9.067360877990723\r\n",
      "[102 210 108 222 218  64  61 114 120 200   4   5 208 111 154 178  40 100\r\n",
      " 104 100 251  52 213  76 150  14  48  16  98  48 116 184  56 132  47 243\r\n",
      "  48 196 217 122 159 104 166 236 108 150 152  78 143  88 148 161 239  22\r\n",
      "  37 210  88 200  14 108 130 164 233 196 204  68 112  48  51 138  86  91\r\n",
      " 200 168  18  56 102 157 156 142 215  62  12  19 148 120 108 163 152 180\r\n",
      " 203 216 152  73   1  66  28  96  77  21   4 142 167  31  99  80 240   0\r\n",
      " 248  72 224 218   8  72  64   9  85 198  47  94  19 206 254 150  40  56\r\n",
      " 108 249 232 125 155  27 209 216 250  25 164 168 192 126  72 191   0 130\r\n",
      " 204 102  68  51 112  91  53 118 128 146 140 201  89  12   0 153 168 122\r\n",
      " 207 137  16 179 192 202  78 120 194   0  80  67 244 238 208 208 215 180\r\n",
      " 134 224 224  37  78 174 196  69  78 103  52 210  64 148 122  64 166 186\r\n",
      " 232 212 246 158  60 125 240  33 104 164 170   2 106 176 184  48  28 222\r\n",
      "  97   2 100 228   0 184  84 252 220 195  34 107 232   8 126 114 144  28\r\n",
      "  52 112  40 249 120 196 180 196 174 218  48 224 130 246   4  74 224  55\r\n",
      " 154  16 230  53]\r\n",
      "Epoch ID=49400 \r\n",
      "\r\n",
      " D-Loss=0.5013805031776428 G-Loss=7.646326065063477\r\n",
      "[ 60 224 180 230  28 122  28 248  86 177  78 170 231  53  14 218 200  54\r\n",
      " 106  64 216 114 109 252  24 192  27 143  76  69 229 129 193 130 250  37\r\n",
      " 128 220 162 252 120 202 136 121 182 159 184  50 230 238 246  83 142  71\r\n",
      " 116 170 184  15 150  96   8 130 166  88 222 104  76  41  41 220 110  34\r\n",
      "  44 188 197 216 192 212  18 244 129  58 178 152 128   5 214 133 200 134\r\n",
      " 111 100  78  12 102 144  10   8 166  78 140  72  22  50  23 199  92 164\r\n",
      "  36  67 108  70 195 107 172 248  62 112  76  46  27 184  58 104 136 206\r\n",
      "  13  57  32 204  36 221 106 168 212  22   2 156  52 188 131  19 154 245\r\n",
      " 110   0   7 103 166  88 138  78 240 204  80  28 155 200  68 100 146  76\r\n",
      "  98 147 100 225 214 132 164 112  90  92 195 136  52   8 156 168 115 252\r\n",
      " 188 220  10 245 186  24 199 122 136   4 184  41 112 212 244 226 222 244\r\n",
      "   1  98 244 229 168 254 240  58 198  28  48  97 142  28  39  79 170  28\r\n",
      " 201 254  56  16 144 211 240 244  74  90 247 172 242 224  73   5 219 144\r\n",
      "  32  70 132 188 135 204  54 184 144 242 134  42 136 208  68  89 142  46\r\n",
      " 114   6 188 156]\r\n",
      "Epoch ID=49500 \r\n",
      "\r\n",
      " D-Loss=0.5165379047393799 G-Loss=8.49468994140625\r\n",
      "[226 214  48  61 195  38 103 176 208 195 254  39 248 254 128 129 102 135\r\n",
      " 239  16 240  27  13 240  41  45 253  63  82   7 118 136  84 152 110 166\r\n",
      " 132  40 165 121 144 165 128 200 130 236 204 228  21 108 114  40  95  33\r\n",
      "  59  96 236 175  94 139 216 255  35  94 172  26  96 213 136  44  94  90\r\n",
      "   0  68 195 181 212  34 158  84 226  24  32 224 110 106 109 202  84  80\r\n",
      " 136 230  70 138 116 170  34 216  90 148  32 228  41 187 142 154  85  51\r\n",
      " 167 116  43 242 149  53  18  95 213 240 140  30 199  55 172 245  29 236\r\n",
      " 188 237 148 117 176 228 204  28 174 194 230 124   4  16 125 239 103  28\r\n",
      " 158 211 169 216 138  56  64  69 130  30 116  86 100  66 248  58 174 118\r\n",
      "  79  66 213 186 140  44  39  92 188 208  26 175  36  60 170 240 246  84\r\n",
      " 203  76 242 154 172 174  48 232   3 164 204  97 235  44 122  68 146  87\r\n",
      " 103  16 175  65  19 210 164  90  76  43 249  86 123  96 155 131  33  18\r\n",
      "   2 240  16 186   6 234 216  44  16 241 250 112 126 105 217 245 221  29\r\n",
      " 214  13 124 202 170  54  98 221  84  42   5 148  22 160 170 199 102 251\r\n",
      "  21 100 214 251]\r\n",
      "Epoch ID=49600 \r\n",
      "\r\n",
      " D-Loss=0.5167508125305176 G-Loss=7.651081085205078\r\n",
      "[ 36  10 242 191  55 176 165 196 178  28 233  58 101  79  23 252 122 202\r\n",
      " 148 214 244  97 159  80  24  15 145 180  94  94  38  12  58   6 244 165\r\n",
      " 111  96 106 170  74 100 238 169 118 138 248 232  20 169 174 116 118 216\r\n",
      "  41 156 109 142 255 171  68 187  54 168  51  82 240 125  43 238 173 232\r\n",
      " 169 216 189 246  38 177  90 124 120 251 131 162 120 254  46 188  16 252\r\n",
      " 214 246  15  36  67 196 176 230  80  52 244  22 143 213  98 220 109 242\r\n",
      " 216  12 231 205 185 206  88 240 194 126 200  39 150 215 151 230  32 196\r\n",
      "  85 209 232 126  95   0 173 159  82   8 185  52 248 248 149  78 182 174\r\n",
      " 231 218 163 210 152  32 128  20  78 110  58 240  20 223  36 143  39  48\r\n",
      "  63   5 100 171 148 114  76   8 252  48 125  87  80   0 140 198 200 205\r\n",
      "  38 114  69 240 138 152  44 124  89  54 168 241 148 204 106  44 184  92\r\n",
      " 100 172 218  14 225 192 160  66 144 228 104 241 236 132   9  43 183  17\r\n",
      "  57 130 200   9 132  63 188  55  62 154 221 174  32 113  51  16  38 158\r\n",
      " 148  60  18 230 174 132  12  71 102 177  90   3  25  56 124 115 172 151\r\n",
      " 122  96 139  80]\r\n",
      "Epoch ID=49700 \r\n",
      "\r\n",
      " D-Loss=0.5153024196624756 G-Loss=9.237483024597168\r\n",
      "[162 226  87 191 145 222  51   6 190 108 200 138 199  96 104 171 100  85\r\n",
      " 130 107   0  92 254  98  63 198 109 246 109 233 127 154  10  10  24  38\r\n",
      "  93 100 226 162   4 130  62 212 204 241 140 136 168 179 231  52   7  37\r\n",
      " 221 232  24 209 120 163 254  12 182  44  87  44  88  38 197 178 230 176\r\n",
      "  19  64 114  40  44  57 126 234 148 115  64 114 157  10 240 189 144 148\r\n",
      " 236 214 148 134 150 110  24 206 243  99 164  38 138  54  58   8 190  20\r\n",
      "  64  12 237 114 228 230 162  36 170  14  26  92 196 195 212 110 127   2\r\n",
      " 111  81 224 132 164 248 233 165 148  71 132  84 188 198  12  27 124  58\r\n",
      " 230 185  56 235  59  72  68 212 240   6 240 145  28 222 155 201  52  32\r\n",
      " 170 152 114 239 180   8 141  50 228 228  74  24 253  32 244  36 182  83\r\n",
      " 140  48 206  97  61   8  19 165 255 231  74  84  37 194  79  66 146  57\r\n",
      "  52 144  89 244  27  39 176 104 142 112  92 197 246   0 202 181 168 102\r\n",
      "  49  79 232 181 111  77 108  84  42  52  70 105 244  29  28 202 236 112\r\n",
      "  76 196  80 131  43  73 248  61  37  39  39 240 149 238 114 165  16 225\r\n",
      " 218 144 243  96]\r\n",
      "Epoch ID=49800 \r\n",
      "\r\n",
      " D-Loss=0.4875381290912628 G-Loss=7.320444583892822\r\n",
      "[ 54  58 128 255 100 106 204 216  37  57 101 140 234 244 250 104 212  70\r\n",
      " 112 106 189  66  72 166  80 240 224 140 199 248 208  72 124 232 188  55\r\n",
      " 232  80  40  79 144  37 204 120  86 112 236 126 228 228   5 119  87 164\r\n",
      "  15 120  79  45 152 156 177 185  62 188  58  18 222  92 135 192 178 128\r\n",
      " 216  44  75  41 247 189 154 124 122   0 241 125 116 169 150 226 232 216\r\n",
      " 126 196 199  42 170 120   8 114 149 121  48 136 116 138 166 194 146 224\r\n",
      "  79 156  49  23  99 184 167 146 170 114 105 108 104 216  76  71 105 209\r\n",
      " 110 195 184  27  57  75 199  39 176  87  24 128  48 220 235 196 147 148\r\n",
      " 108 146 107  46 245  78 165 214 137  38  92 155 235 248  28 236 154  92\r\n",
      "  96 106 252 149 172  52 170   4  20 188 238  64  52  96  16 222   0  74\r\n",
      "  79 120 112 242 188 184  81  92 253 101  96  40 201 116 147  36 110 144\r\n",
      " 245  24 231 112 110   4  14 240 226 142  46  11  90 108 206 206 166  16\r\n",
      " 251 204  29 110 184  67  54  32 200  36  16 179 180  22  44 116 166   2\r\n",
      " 236  68 238  90 186 148 180 229 158 219 136 120  80  87 226  74  77  44\r\n",
      " 232  46 166 213]\r\n",
      "Epoch ID=49900 \r\n",
      "\r\n",
      " D-Loss=0.48751938343048096 G-Loss=9.521076202392578\r\n"
     ]
    }
   ],
   "source": [
    "#STEPS = [3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "STEPS = [50000]\n",
    "for step in STEPS:\n",
    "    for i in range(1):\n",
    "        outparmfile =\"work/\"+'SoftSignBignewnewbce'+str(i)+\"generator-steps\"+str(step)+\".params\"\n",
    "        train(outparmfile, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f33932-b7a2-4c4b-8c5f-af47807dc97a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
